{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This module is exlusive to google colab and should not be used on local notebook."
      ],
      "metadata": {
        "id": "9vwuglVunSRM"
      },
      "id": "9vwuglVunSRM"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install impyute"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YTOPv6EuIEu",
        "outputId": "5368c598-b353-4158-eb36-5782d2421b4c"
      },
      "id": "4YTOPv6EuIEu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting impyute\n",
            "  Downloading impyute-0.0.8-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from impyute) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from impyute) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from impyute) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->impyute) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->impyute) (1.1.0)\n",
            "Installing collected packages: impyute\n",
            "Successfully installed impyute-0.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46ed5885",
      "metadata": {
        "scrolled": false,
        "id": "46ed5885"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "from collections import defaultdict\n",
        "from scipy.stats import spearmanr\n",
        "from scipy.cluster import hierarchy\n",
        "from scipy.spatial.distance import squareform\n",
        "\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from impyute.imputation.cs import mice\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import (train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, \n",
        "RepeatedStratifiedKFold, StratifiedKFold)\n",
        "from sklearn.model_selection import StratifiedGroupKFold, permutation_test_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE, Isomap\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, accuracy_score,roc_curve, f1_score, precision_score, recall_score, silhouette_score\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# import datawig\n",
        "# Machine Learning Algorithms\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import lightgbm as lgb\n",
        "from sklearn import tree\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture as GMM\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "\n",
        "#pd.options.display.max_rows = 999\n",
        "pd.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aed9f3df",
      "metadata": {
        "id": "aed9f3df"
      },
      "source": [
        "# Imputation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a12b848",
      "metadata": {
        "id": "3a12b848"
      },
      "outputs": [],
      "source": [
        "def mice_imputation(df_cleaned):\n",
        "    \n",
        "    #Preparing measurement values by putting them into new df to impute them later\n",
        "    X = df_cleaned[df_cleaned.columns[8:]]\n",
        "\n",
        "    imputed = mice(X.values)\n",
        "    df_mice = pd.DataFrame(imputed)\n",
        "    \n",
        "    # Merging non-measurement features with non-outlier dataframe\n",
        "    #df_mice.columns = df_cleaned.columns[9:]\n",
        "    df_mice = pd.concat([df_cleaned[df_cleaned.columns[:8]], df_mice], ignore_index=True, axis=1)\n",
        "    df_mice.columns = df_cleaned.columns\n",
        "    return df_mice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffe2991b",
      "metadata": {
        "id": "ffe2991b"
      },
      "outputs": [],
      "source": [
        "def iter_imputation(df_cleaned):\n",
        "    df_cleaned.reset_index(drop=True,inplace=True)\n",
        "    data_iter =  df_cleaned.iloc[:,9:]\n",
        "    # print total missing\n",
        "    print('Missing: %d' % df_cleaned.isnull().sum().sum())\n",
        "    # define imputer\n",
        "    imputer = IterativeImputer(n_nearest_features=3, imputation_order='ascending')\n",
        "\n",
        "    # fit and transform the dataset\n",
        "    Xtrans = imputer.fit_transform(data_iter)\n",
        "    # print total missing\n",
        "    print('Missing: %d' % np.count_nonzero(np.isnan(Xtrans)))\n",
        "    \n",
        "    # Merging non-measurement features with filled measurement into df\n",
        "\n",
        "    df_Xtrans= pd.DataFrame(Xtrans)             \n",
        "    df_iter_imputation = pd.concat([df_cleaned[df_cleaned.columns[:9]], df_Xtrans], ignore_index=True, axis=1)\n",
        "    df_iter_imputation.columns = df_cleaned.columns\n",
        "    \n",
        "    \n",
        "    return df_iter_imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bba6e75",
      "metadata": {
        "id": "7bba6e75"
      },
      "outputs": [],
      "source": [
        "# def iter_imputation(df_cleaned):\n",
        "    \n",
        "#     data_iter =  df_cleaned.drop(df_cleaned.iloc[:, 0:9], axis= 1)\n",
        "#     # split into input and output elements\n",
        "#     df_cleaned_values = data_iter.values\n",
        "#     ix = [i for i in range(data_iter.shape[1]) if i != 0 ]\n",
        "#     # X, y = df_cleaned_values[:, ix], df_cleaned_values[:, 0]\n",
        "#     X, y = df_cleaned_values, df_cleaned_values[:, 0]\n",
        "\n",
        "#     # print total missing\n",
        "#     print('Missing: %d' % df_cleaned.isnull().sum().sum())\n",
        "#     # define imputer\n",
        "#     imputer = IterativeImputer(estimator=BayesianRidge(), n_nearest_features=3, imputation_order='ascending',random_state=0)\n",
        "#     # fit on the dataset\n",
        "#     imputer.fit(X)\n",
        "#     # transform the dataset\n",
        "#     Xtrans = imputer.transform(X)\n",
        "#     # print total missing\n",
        "#     print('Missing: %d' % np.count_nonzero(np.isnan(Xtrans)))\n",
        "    \n",
        "#     # Merging non-measurement features with filled measurement into df\n",
        "\n",
        "#     df_Xtrans= pd.DataFrame(Xtrans)             \n",
        "#     df_iter_imputation = pd.concat([df_cleaned[df_cleaned.columns[:9]], df_Xtrans], ignore_index=True, axis=1)\n",
        "#     df_iter_imputation.columns = df_cleaned.columns\n",
        "    \n",
        "    \n",
        "#     return df_iter_imputation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dab1def",
      "metadata": {
        "id": "1dab1def"
      },
      "source": [
        "# Outlier Count Per Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82e46451",
      "metadata": {
        "id": "82e46451"
      },
      "outputs": [],
      "source": [
        "def outlierCountbyRow(df):\n",
        "    \n",
        "    Q1 = df[df.columns[9:]].quantile(0.25)\n",
        "    Q3 = df[df.columns[9:]].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    \n",
        "    df_last_mea = df[df.columns[9:]]\n",
        "    df_last_mea = df_last_mea.fillna(df_last_mea.mean())\n",
        "    outlier_matrix = ((df_last_mea < (Q1_notLike - 1.5 * IQR_notLike)) | (df_last_mea > (Q3_notLike + 1.5 * IQR_notLike)))\n",
        "    \n",
        "    outlier_count = outlier_matrix.sum(axis=0)\n",
        "    outlier_percent = 100 * outlier_matrix.sum(axis=0) / df_last_mea.shape[0]\n",
        "    \n",
        "    # Df\n",
        "    outlier_df = pd.concat([outlier_count, outlier_percent],\n",
        "                              axis=1)\n",
        "    \n",
        "    outlier_df_final = outlier_df.rename(\n",
        "        columns={0: 'Outlier Count', 1: '% of Total Values'})\n",
        "    \n",
        "    # Sort the table by percentage of outlier count descending\n",
        "    outlier_df_final = (outlier_df_final[\n",
        "        outlier_df_final.iloc[:, 1] != 0].sort_values(\n",
        "        '% of Total Values', ascending=False).round(1))\n",
        "    return outlier_df_final"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5864cce",
      "metadata": {
        "id": "d5864cce"
      },
      "source": [
        "# Missing Values Per Row Indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "077d468c",
      "metadata": {
        "id": "077d468c"
      },
      "outputs": [],
      "source": [
        "def missingValuesRows(df):\n",
        "    # Total missing values\n",
        "    mis_val = df.isnull().sum(axis=1)\n",
        "\n",
        "    # Percentage of missing values\n",
        "    mis_val_percent = 100 * df.isnull().sum(axis=1) / df.shape[1]\n",
        "\n",
        "    # Make a table with the results\n",
        "    mis_val_table = pd.concat([mis_val, mis_val_percent],\n",
        "                              axis=1)\n",
        "\n",
        "    # Rename the columns\n",
        "    mis_val_table_ren_rows = mis_val_table.rename(\n",
        "        columns={0: 'Missing Values', 1: '% of Total Values'})\n",
        "\n",
        "    # Sort the table by percentage of missing descending\n",
        "    mis_val_table_ren_rows = (mis_val_table_ren_rows[\n",
        "        mis_val_table_ren_rows.iloc[:, 1] != 0].sort_values(\n",
        "        '% of Total Values', ascending=False).round(1))\n",
        "\n",
        "    # Print some summary information\n",
        "    print(\"Your selected dataframe has \" + str(df.shape[0]) + \" columns.\\n\"\n",
        "          \"There are \" + str(mis_val_table_ren_rows.shape[0]) +\n",
        "          \" columns that have missing values.\")\n",
        "\n",
        "    # Return the dataframe with missing information\n",
        "    return mis_val_table_ren_rows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4772c40d",
      "metadata": {
        "id": "4772c40d"
      },
      "source": [
        "# Missing Value Per Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cad8b63",
      "metadata": {
        "id": "7cad8b63"
      },
      "outputs": [],
      "source": [
        "def missing_values_table(df):\n",
        "    # Total missing values\n",
        "    mis_val = df.isnull().sum()\n",
        "\n",
        "    # Percentage of missing values\n",
        "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
        "\n",
        "    # Make a table with the results\n",
        "    mis_val_table = pd.concat([mis_val, mis_val_percent],\n",
        "                              axis=1)\n",
        "\n",
        "    # Rename the columns\n",
        "    mis_val_table_ren_columns = mis_val_table.rename(\n",
        "        columns={0: 'Missing Values', 1: '% of Total Values'})\n",
        "\n",
        "    # Sort the table by percentage of missing descending\n",
        "    mis_val_table_ren_columns = (mis_val_table_ren_columns[\n",
        "        mis_val_table_ren_columns.iloc[:, 0] != 0].sort_values(\n",
        "        '% of Total Values', ascending=False).round(1))\n",
        "\n",
        "    # Print some summary information\n",
        "    print(\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"\n",
        "          \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
        "          \" columns that have missing values.\")\n",
        "\n",
        "    # Return the dataframe with missing information\n",
        "    return mis_val_table_ren_columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd25c0f8",
      "metadata": {
        "id": "cd25c0f8"
      },
      "source": [
        "# Outlier Removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d9f343",
      "metadata": {
        "id": "e6d9f343"
      },
      "outputs": [],
      "source": [
        "def outlier_removal(df_last):\n",
        "    \n",
        "    Q1 = df_last[df_last.columns[9:]].quantile(0.25)\n",
        "    Q3 = df_last[df_last.columns[9:]].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # Outlier dataframe, True means it is an outlier\n",
        "    df_out = (df_last[df_last.columns[9:]] < (Q1 - 1.5 * IQR)) | (df_last[df_last.columns[9:]] > (Q3 + 1.5 * IQR))\n",
        "    true_count = ( df_out == True ).sum(axis=1).sum()\n",
        "    false_count = ( df_out == False ).sum(axis=1).sum()\n",
        "    print(\"True count: {} False Count: {}\".format(true_count,false_count))\n",
        "\n",
        "    # to check if all values of a row has outlier\n",
        "    print(df_out.shape, df_out[~df_out.all(1)].shape)\n",
        "\n",
        "    # Transforming outliers into NaN    \n",
        "    df_last_mea = df_last[df_last.columns[9:]]\n",
        "    df_out = df_last_mea.mask(((df_last_mea < (Q1 - 1.5 * IQR)) |(df_last_mea > (Q3 + 1.5 * IQR))))\n",
        "    \n",
        "    # Adding non-measurement columns\n",
        "    df_last_out = pd.concat([df_last[df_last.columns[:9]], df_out], ignore_index=True, axis=1)\n",
        "    df_last_out.columns = df_last.columns\n",
        "    \n",
        "    return df_last_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dd54f86",
      "metadata": {
        "id": "1dd54f86"
      },
      "outputs": [],
      "source": [
        "def avg_lr(df):\n",
        "    df_avg_lr = df.copy()\n",
        "    df_avg_lr.drop(df_avg_lr.iloc[:,9:], inplace=True, axis=1)\n",
        "\n",
        "    df_avg_lr['Goxy_Avg'] = df.iloc[:,9:17].mean(axis=1) / df.iloc[:,17:25].mean(axis=1)\n",
        "    df_avg_lr['Ghbr_Avg'] = df.iloc[:,25:33].mean(axis=1) / df.iloc[:,33:41].mean(axis=1)\n",
        "    df_avg_lr['Ghbo_Avg'] = df.iloc[:,41:49].mean(axis=1) / df.iloc[:,49:57].mean(axis=1)\n",
        "    df_avg_lr['Ghbt_Avg'] = df.iloc[:,57:65].mean(axis=1) / df.iloc[:,65:73].mean(axis=1)\n",
        "\n",
        "    df_avg_lr['Koxy_Avg'] = df.iloc[:,73:81].mean(axis=1) / df.iloc[:,81:89].mean(axis=1)\n",
        "    df_avg_lr['Khbr_Avg'] = df.iloc[:,89:97].mean(axis=1) / df.iloc[:,97:105].mean(axis=1)\n",
        "    df_avg_lr['Khbo_Avg'] = df.iloc[:,105:113].mean(axis=1) / df.iloc[:,113:121].mean(axis=1)\n",
        "    df_avg_lr['Khbt_Avg'] = df.iloc[:,121:129].mean(axis=1) / df.iloc[:,129:137].mean(axis=1)\n",
        "\n",
        "    # df_avg_lr['Goxy_Avg9-16'] = df_cleaned.iloc[:,25:33].mean(axis=1)\n",
        "    return df_avg_lr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55f0c4a6",
      "metadata": {
        "id": "55f0c4a6"
      },
      "source": [
        "# Kmeans & GMM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3484f6f9",
      "metadata": {
        "id": "3484f6f9"
      },
      "outputs": [],
      "source": [
        "def amountByCluster(df,clusterNum):\n",
        "    df_prc = pd.DataFrame(df_avgiter_GMM_onehot_cl2.iloc[:,-clusterNum:].sum())\n",
        "    df_prc[1] = 0\n",
        "    for i in range(0,clusterNum):\n",
        "        df_prc.iloc[i,1] = df_prc.iloc[i,0] / df_prc.iloc[:,0].sum() * 100\n",
        "\n",
        "    return df_prc.sort_values(by=0, ascending=False)\n",
        "\n",
        "\n",
        "def gmm_js(gmm_p, gmm_q, n_samples=10**5):\n",
        "    X = gmm_p.sample(n_samples)[0]\n",
        "    log_p_X = gmm_p.score_samples(X)\n",
        "    log_q_X = gmm_q.score_samples(X)\n",
        "    log_mix_X = np.logaddexp(log_p_X, log_q_X)\n",
        "\n",
        "    Y = gmm_q.sample(n_samples)[0]\n",
        "    log_p_Y = gmm_p.score_samples(Y)\n",
        "    log_q_Y = gmm_q.score_samples(Y)\n",
        "    log_mix_Y = np.logaddexp(log_p_Y, log_q_Y)\n",
        "\n",
        "    return np.sqrt((log_p_X.mean() - (log_mix_X.mean() - np.log(2))\n",
        "            + log_q_Y.mean() - (log_mix_Y.mean() - np.log(2))) / 2)\n",
        "\n",
        "def df_Kmeans_evaluation(df):\n",
        "    \n",
        "    df_age_sex = pd.read_csv(r'/content/drive/MyDrive/Master/Tez/FNIRS_bilgi.csv')\n",
        "    df_age_sex.columns = ['Part_No', 'Gender', 'Age', 'Education']\n",
        "    \n",
        "    # Merging gender data with main data\n",
        "    df_whole = pd.merge(df_age_sex, \n",
        "                          df, \n",
        "                          on ='Part_No', \n",
        "                          how ='inner')\n",
        "    \n",
        "    # Gender One Hot Encoding\n",
        "    One_enc = OneHotEncoder(handle_unknown='ignore')\n",
        "    enc_df = pd.DataFrame(One_enc.fit_transform(df_whole[['Gender']]).toarray())\n",
        "    df_whole = df_whole.join(enc_df)\n",
        "    df_whole.rename(columns = {0:'Male', 1:'Female'}, inplace = True)\n",
        "    \n",
        "    Z = df_whole.groupby(['Part_No'], as_index = False).mean()\n",
        "    \n",
        "#     s_scores = []\n",
        "#     for i in range(2,10):\n",
        "#         KMean = KMeans(n_clusters=i)\n",
        "#         KMean.fit(Z.iloc[:,8:16])\n",
        "#         label = KMean.predict(Z.iloc[:,8:16])\n",
        "#         print(f'Silhouette Score(n={i}): {silhouette_score(Z.iloc[:,8:16], label)}')\n",
        "#         s_scores.append(silhouette_score(Z.iloc[:,8:16], label))\n",
        "#     plt.plot(np.arange(2,20), s_scores)\n",
        "#     plt.title('Silhouette Score of K-Means')\n",
        "#     plt.xlabel('Cluster Number')\n",
        "#     plt.ylabel('Sİlhouette Score')\n",
        "#     plt.show()\n",
        "\n",
        "    # Silhouette Score\n",
        "    n_components = np.arange(2, 20)\n",
        "    models = [KMeans(n_clusters = n).fit(Z.iloc[:,9:]) for n in n_components]\n",
        "    labels = [model.predict(Z.iloc[:,9:]) for model in models]\n",
        "    plt.plot(n_components, [silhouette_score(Z.iloc[:,9:], label) for label in labels] )\n",
        "    plt.title('Silhouette Score of K-Means')\n",
        "    plt.xlabel('Cluster Number')\n",
        "    plt.ylabel('Silhouette Score')\n",
        "    plt.xticks(np.arange(1,20,1))\n",
        "    plt.show()\n",
        "    \n",
        "def df_Kmeans_silhouette(df, clusters):\n",
        "    \n",
        "    df_age_sex = pd.read_csv(r'/content/drive/MyDrive/Master/Tez/FNIRS_bilgi.csv')\n",
        "    df_age_sex.columns = ['Part_No', 'Gender', 'Age', 'Education']\n",
        "    \n",
        "    # Merging gender data with main data\n",
        "    df_whole = pd.merge(df_age_sex, \n",
        "                          df, \n",
        "                          on ='Part_No', \n",
        "                          how ='inner')\n",
        "    \n",
        "    # Gender One Hot Encoding\n",
        "    One_enc = OneHotEncoder(handle_unknown='ignore')\n",
        "    enc_df = pd.DataFrame(One_enc.fit_transform(df_whole[['Gender']]).toarray())\n",
        "    df_whole = df_whole.join(enc_df)\n",
        "    df_whole.rename(columns = {0:'Male', 1:'Female'}, inplace = True)\n",
        "    Z = df_whole.groupby(['Part_No'], as_index = False).mean()\n",
        "\n",
        "    # K-means Clustering and its One Hot Encoding\n",
        "    KMean = KMeans(n_clusters=clusters)\n",
        "    KMean.fit(Z.iloc[:,9:])\n",
        "    label = KMean.predict(Z.iloc[:,9:])\n",
        "    Z['Clusters'] = label\n",
        "    Z = Z[['Part_No']].join(Z['Clusters'])    \n",
        "    df_whole = pd.merge(df_whole, \n",
        "                          Z, \n",
        "                          on ='Part_No', \n",
        "                          how ='inner')    \n",
        "    One_enc_2 = OneHotEncoder(handle_unknown='ignore')\n",
        "    enc_df_2 = pd.DataFrame(One_enc_2.fit_transform(df_whole[['Clusters']]).toarray())\n",
        "    df_whole = df_whole.join(enc_df_2)    \n",
        "#     df_whole.rename(columns = {0:'Cluster 1', 1:'Cluster 2'}, inplace = True)    \n",
        "    df_whole.drop(['Clusters', 'Gender', 'Age', 'Education'], inplace = True, axis = 1)\n",
        "    \n",
        "    return df_whole    \n",
        "\n",
        "\n",
        "def df_GMM_evaluation(df):\n",
        "    \n",
        "    df_age_sex = pd.read_csv(r'/content/drive/MyDrive/Master/Tez/FNIRS_bilgi.csv')\n",
        "    df_age_sex.columns = ['Part_No', 'Gender', 'Age', 'Education']\n",
        "    \n",
        "    # Merging gender data with main data\n",
        "    df_whole = pd.merge(df_age_sex, \n",
        "                          df, \n",
        "                          on ='Part_No', \n",
        "                          how ='inner')\n",
        "    \n",
        "    # Gender One Hot Encoding\n",
        "    One_enc = OneHotEncoder(handle_unknown='ignore')\n",
        "    enc_df = pd.DataFrame(One_enc.fit_transform(df_whole[['Gender']]).toarray())\n",
        "    df_whole = df_whole.join(enc_df)\n",
        "    df_whole.rename(columns = {0:'Male', 1:'Female'}, inplace = True)\n",
        "    Z = df_whole.groupby(['Part_No'], as_index = False).mean()\n",
        "    \n",
        "\n",
        "    # Silhouette Score\n",
        "#     n_components = np.arange(2, 20)\n",
        "#     models = [GMM(n_components = n, covariance_type='full').fit(Z.iloc[:,9:]) for n in n_components]\n",
        "#     labels = [model.predict(Z.iloc[:,9:]) for model in models]\n",
        "#     plt.plot(n_components, [silhouette_score(Z.iloc[:,9:], label) for label in labels] )\n",
        "#     plt.title('Silhouette Score of GMM')\n",
        "#     plt.xlabel('Cluster Number')\n",
        "#     plt.ylabel('Silhouette Score')\n",
        "#     plt.xticks(np.arange(1,20,1))\n",
        "#     plt.show()\n",
        "    \n",
        "    # BIC/AIC Score\n",
        "    n_components_ = np.arange(2, 20)\n",
        "    models = [GMM(n, covariance_type='full', random_state=0).fit(Z.iloc[:,9:])\n",
        "          for n in n_components_]\n",
        "\n",
        "    plt.plot(n_components_, [m.bic(Z.iloc[:,9:]) for m in models], label='BIC')\n",
        "    plt.plot(n_components_, [m.aic(Z.iloc[:,9:]) for m in models], label='AIC')\n",
        "    plt.legend(loc='best')\n",
        "    plt.title('BIC AIC Evaluation')\n",
        "    plt.xlabel('n_components')\n",
        "    plt.ylabel('Score')\n",
        "    plt.xticks(np.arange(1,20,1))\n",
        "    plt.show()\n",
        "    \n",
        "    #Jensen Shannon Divergence Score/Distances\n",
        "#     js_scores = []\n",
        "#     for n in n_components_:\n",
        "#         train, test = train_test_split(Z.iloc[:,9:], test_size=0.5)\n",
        "#         norm = MinMaxScaler()\n",
        "#         train_norm = norm.fit_transform(train).reshape(-1,1)\n",
        "#         test_norm = norm.transform(test).reshape(-1,1)\n",
        "#         gmm_train = GMM(n_components = n, covariance_type='full' ).fit(train_norm) \n",
        "#         gmm_test = GMM(n_components = n, covariance_type='full').fit(test_norm) \n",
        "#         js_scores.append(gmm_js(gmm_train, gmm_test))    \n",
        "    \n",
        "#     plt.plot(n_components, js_scores)\n",
        "#     plt.title('Jensen Shannon Divergence GMM')\n",
        "#     plt.xlabel('Cluster Number')\n",
        "#     plt.ylabel('Distance')\n",
        "#     plt.xticks(np.arange(1,20,1))\n",
        "#     plt.show()\n",
        "    \n",
        "\n",
        "def df_GMM(df, clusters):\n",
        "    \n",
        "    df_age_sex = pd.read_csv(r'/content/drive/MyDrive/Master/Tez/FNIRS_bilgi.csv')\n",
        "    df_age_sex.columns = ['Part_No', 'Gender', 'Age', 'Education']\n",
        "    \n",
        "    # Merging gender data with main data\n",
        "    df_whole = pd.merge(df_age_sex, \n",
        "                          df,  \n",
        "                          on ='Part_No', \n",
        "                          how ='inner')\n",
        "    \n",
        "    # Gender One Hot Encoding\n",
        "    One_enc = OneHotEncoder(handle_unknown='ignore')\n",
        "    enc_df = pd.DataFrame(One_enc.fit_transform(df_whole[['Gender']]).toarray())\n",
        "    df_whole = df_whole.join(enc_df)\n",
        "    df_whole.rename(columns = {0:'Male', 1:'Female'}, inplace = True)\n",
        "    Z = df_whole.groupby(['Part_No'], as_index = False).mean()\n",
        "    \n",
        "    # GMM Clustering and its One Hot Encoding\n",
        "    GMM_ = GMM(n_components = clusters, covariance_type='full' ).fit(Z.iloc[:,9:]) \n",
        "    label = GMM_.predict(Z.iloc[:,9:])\n",
        "    Z['Clusters'] = label    \n",
        "    Z = Z[['Part_No']].join(Z['Clusters'])\n",
        "    df_whole = pd.merge(df_whole, \n",
        "                          Z, \n",
        "                          on ='Part_No', \n",
        "                          how ='inner')    \n",
        "    One_enc_2 = OneHotEncoder(handle_unknown='ignore')\n",
        "    enc_df_2 = pd.DataFrame(One_enc_2.fit_transform(df_whole[['Clusters']]).toarray())\n",
        "    df_whole = df_whole.join(enc_df_2)\n",
        "#     df_whole.rename(columns = {0:'Cluster 1', 1:'Cluster 2'}, inplace = True)\n",
        "    \n",
        "    # Dropping unnecassary columns as to make it same shape as other data\n",
        "    df_whole.drop(['Clusters', 'Gender', 'Age', 'Education'], inplace = True, axis = 1)\n",
        "\n",
        "    return df_whole"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35d32df1",
      "metadata": {
        "id": "35d32df1"
      },
      "source": [
        "# Permutation Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37421aab",
      "metadata": {
        "id": "37421aab"
      },
      "outputs": [],
      "source": [
        "def permutationTest(model, X_train, Y_train, cv, groups):\n",
        "    score, perm_scores, pvalue = permutation_test_score(\n",
        "    model, X_train, Y_train, groups=groups, scoring=\"f1\", cv=cv, n_permutations=50)\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    ax.hist(perm_scores, bins=20, density=True)\n",
        "    ax.axvline(score, ls=\"--\", color=\"r\")\n",
        "    score_label = f\"Score on original\\ndata: {score:.2f}\\n(p-value: {pvalue:.4f})\"\n",
        "    ax.text(0.7, 10, score_label, fontsize=12)\n",
        "    ax.set_xlabel(\"F1 score\")\n",
        "    ax.set_ylabel(\"Probability\")\n",
        "    plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbb87349",
      "metadata": {
        "id": "fbb87349"
      },
      "outputs": [],
      "source": [
        "def permutation_importance(model_, X_pca_train, Y_train):   \n",
        "    # perform permutation importance\n",
        "    results = permutation_importance(model_, X_pca_train, Y_train, scoring='accuracy')\n",
        "    # get importance\n",
        "    importance = results.importances_mean\n",
        "    # summarize feature importance\n",
        "    for i,v in enumerate(importance):\n",
        "        print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "    # plot feature importance\n",
        "    plt.bar([x for x in range(len(importance))], importance)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "IH4lokeJ1gWA",
        "outputId": "5f6241fc-77f1-4834-dc11-5782c0730044"
      },
      "id": "IH4lokeJ1gWA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-70b85a2ac500>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Value'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Value2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Value3'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXPLANIED VARIANCE RATIO AND FEATURE NUMBER"
      ],
      "metadata": {
        "id": "VGQ5TM_ignwy"
      },
      "id": "VGQ5TM_ignwy"
    },
    {
      "cell_type": "code",
      "source": [
        "def n_to_reach(df,featureCount, variance):\n",
        "    \n",
        "    print('Finding feature number to be reduced to given the explained variance ratio...')\n",
        "    df = pd.concat([df[df.columns[8:]], df[df.columns[6]]], ignore_index=True, axis=1)\n",
        "    i = df.shape[1] - (featureCount + 1)\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    df.iloc[:,1:-i], df.iloc[:,0], test_size=0.2, random_state=0)\n",
        "        \n",
        "    # finding n_components for maintaining specified variance\n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    print(\"Starting PCA...\")\n",
        "    start = time.time()\n",
        "    pca = PCA()    \n",
        "    X_pca_train = pca.fit_transform(X_train_scaled)\n",
        "    \n",
        "    total_explained_variance = pca.explained_variance_ratio_.cumsum()\n",
        "    n_over = len(total_explained_variance[total_explained_variance >= variance])\n",
        "    n_to_reach = X_train.shape[1] - n_over + 1\n",
        "    print(\"Number features: {}\\tTotal Variance Explained: {}\"\n",
        "          .format(n_to_reach, total_explained_variance[n_to_reach-1]))\n",
        "    return n_to_reach"
      ],
      "metadata": {
        "id": "W7_yR8xbgF8b"
      },
      "id": "W7_yR8xbgF8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2df6538e",
      "metadata": {
        "id": "2df6538e"
      },
      "source": [
        "# MAIN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fe6744e",
      "metadata": {
        "id": "6fe6744e"
      },
      "outputs": [],
      "source": [
        "def main_model(df, model, model_name, featureCount, SMOTEBool=False):\n",
        "    \n",
        "    df = pd.concat([df[df.columns[8:]], df[df.columns[6]]], ignore_index=True, axis=1)\n",
        "    i = df.shape[1] - (featureCount + 1)\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    df.iloc[:,1:-i], df.iloc[:,0], test_size=0.20, random_state=0)\n",
        "    print('MAIN RESULTS')\n",
        "    \n",
        "    param_grid = {}\n",
        "    pos_weight = sum(Y_train[Y_train == 0]) / sum(Y_train[Y_train == 1])\n",
        "    train_weight = sum(1 if x == 0 else 0 for x in Y_train)\\\n",
        "                        /sum(1 if x == 1 else 0 for x in Y_train)\n",
        "    # Parameter tuning\n",
        "    if model_name == 'lgb':\n",
        "        \n",
        "        param_grid = {\n",
        "                    'boosting_type': ['dart'],\n",
        "                    'num_leaves': [16,48,96],\n",
        "                    'learning_rate': [0.01,0.03],\n",
        "                    'max_depth': [2, 3, 4],\n",
        "                    'max_bin': [500,1000],\n",
        "#                     'n_estimators' : [500,1000]\n",
        "#                 'boosting_type': ['gbdt', 'goss', 'dart'],\n",
        "#                 'num_leaves': list(range(10, 20)),\n",
        "#                 'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
        "#                 'max_depth':list(range(1,12)),\n",
        "#                 'max_bin': list(range(2, 30)),\n",
        "                'num_iterations': list(range(50, 100)),\n",
        "                'early_stopping_rounds': list(range(1, 10)),\n",
        "                'scale_pos_weight': [pos_weight],\n",
        "                'n_jobs' : [-1],\n",
        "                'path_smooth': list(range(2,15)),\n",
        "                'random_state': [0]\n",
        "                     }\n",
        "    \n",
        "    elif model_name == 'rfc':\n",
        "        \n",
        "        param_grid = {'bootstrap': [True],\n",
        "                       'max_depth': [2, 3, 4],\n",
        "                       'n_estimators': [100, 300, 500],\n",
        "                       'criterion' :['gini', 'entropy']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'SVM':\n",
        "        \n",
        "        param_grid = {'C': [0.01, 0.1, 1, 3, 5],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['linear']\n",
        "                     }\n",
        "        \n",
        "    \n",
        "    elif model_name == 'KNN':\n",
        "        \n",
        "        param_grid = {'n_neighbors': list(range(3,21)),\n",
        "              'metric': ['euclidean']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'XGB':\n",
        "        \n",
        "        \n",
        "        \n",
        "        param_grid = {'learning_rate':[0.01, 0.03, 0.05, 0.1],\n",
        "                'max_depth':[2,3,4],\n",
        "                'booster': ('gbtree', 'gblinear'),\n",
        "                'random_state': [0],\n",
        "                'n_jobs': [-1],\n",
        "                'scale_pos_weight': [pos_weight],\n",
        "                'gamma': [1, 5, 10],\n",
        "                'min_child_weight': list(range(3,8)),\n",
        "                'use_label_encoder': [False],\n",
        "                'early_stopping_rounds': list(range(3,10)),\n",
        "                'objective': ['binary:logistic'], \n",
        "                'eval_metric': ['auc'],\n",
        "                'verbosity': [0]\n",
        "                     }\n",
        "        \n",
        "        \n",
        "        \n",
        "       \n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    \n",
        "    # Normalization\n",
        "#     scaler = MinMaxScaler()\n",
        "    \n",
        "    \n",
        "    # Pipeline\n",
        "#     pipe = Pipeline([('scaler', scaler),\n",
        "#                      ('clf', model)])\n",
        "\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_train_scaled = pd.DataFrame(X_train_scaled)\n",
        "    X_train_scaled.index = X_train.index\n",
        "    X_train = pd.merge(X_train_scaled, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_train.columns = np.arange(X_train.shape[1])\n",
        "    \n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    X_test_scaled = pd.DataFrame(X_test_scaled)\n",
        "    X_test_scaled.index = X_test.index\n",
        "    X_test = pd.merge(X_test_scaled, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_test.columns = np.arange(X_test.shape[1])\n",
        "    X_test = X_test.iloc[:,:-1]\n",
        "\n",
        "   \n",
        "    groups = X_train.iloc[:,-1]\n",
        "    X_train = X_train.iloc[:,:-1]\n",
        "\n",
        "    \n",
        "    #SMOTE for Train Data to Balance Dataset and also to Increase Data Size\n",
        "    if SMOTEBool == True:\n",
        "        print('SMOTE is being applied to the train set...')\n",
        "        oversample = SMOTE()\n",
        "        X_train, Y_train = oversample.fit_resample(X_train, Y_train)\n",
        "    \n",
        "    # K-fold cross validation\n",
        "    print('Starting StratifiedGroupKFold...')\n",
        "    start = time.time()\n",
        "    cv = StratifiedGroupKFold(n_splits=5, random_state=1, shuffle=True)\n",
        "    cv_results = cross_val_score(model, X_train, Y_train, groups=groups, cv=cv, scoring='accuracy')\n",
        "    print('Cross Validation Accuracy: %.3f (%.3f)' % (np.mean(cv_results), np.std(cv_results)))\n",
        "    end = time.time()\n",
        "    print(f\"Total Time of StratifiedGroupKFold = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "    \n",
        "    # GridSearch for Hyperparameters\n",
        "    print(\"Starting fitting into the model...\")\n",
        "    start = time.time()\n",
        "    model_ = GridSearchCV(model,           # model\n",
        "              param_grid = param_grid,    # hyperparameters\n",
        "              scoring='accuracy',         # metric for scoring\n",
        "              cv=cv,                      # number of folds\n",
        "              n_jobs=-1)             \n",
        "    model_.fit(X_train, Y_train, groups=groups)\n",
        "    end = time.time()\n",
        "    print(f\"Total Time of model fit = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "\n",
        "    model.set_params(**model_.best_params_)\n",
        "    print(model.get_params())\n",
        "    \n",
        "    #permutationTest(model, X_train, Y_train, cv, groups)\n",
        "    \n",
        "#     # perform permutation importance\n",
        "#     results = permutation_importance(model_, X_train, Y_train, scoring='accuracy')\n",
        "#     # get importance\n",
        "#     importance = results.importances_mean\n",
        "#     # summarize feature importance\n",
        "#     for i,v in enumerate(importance):\n",
        "#         print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "#     # plot feature importance\n",
        "#     plt.bar([x for x in range(len(importance))], importance)\n",
        "#     plt.show()\n",
        "    \n",
        "    print(\"Tuned Hyperparameters :\", model_.best_params_)\n",
        "#     print(\"Tuned Best Accuracy :\", model_.best_score_)\n",
        "    \n",
        "    # Predictions\n",
        "    pred_prob = model_.predict_proba(X_test)\n",
        "#     print(pred_prob)\n",
        "\n",
        "    # keep probabilities for the positive outcome only\n",
        "    pred_prob = pred_prob[:, 1]\n",
        "#     print(pred_prob_pos)\n",
        "    \n",
        "    # calculate roc curves\n",
        "    fpr, tpr, thresholds = roc_curve(Y_test, pred_prob)\n",
        "    \n",
        "    # calculate the g-mean for each threshold\n",
        "    gmeans = np.sqrt(tpr * (1-fpr))\n",
        "    \n",
        "    # locate the index of the largest g-mean\n",
        "    ix = np.argmax(gmeans)\n",
        "#     print('Best Threshold = %f, G-Mean = %.3f' % (thresholds[ix], gmeans[ix]))\n",
        "    print('Train Accuracy Score:', model_.score(X_train, Y_train))   \n",
        "    \n",
        "    # Probability of predictions adjusted to new threshold\n",
        "    predict_model = [1 if y >= thresholds[ix] else 0 for y in pred_prob]\n",
        "    \n",
        "    # Original threshold\n",
        "#     predict_model = [1 if y >= 0.5 else 0 for y in pred_prob]\n",
        "#     print(predict_model)\n",
        "\n",
        "    \n",
        "    #print(predict_lgb)\n",
        "    print('Test Accuracy Score:', accuracy_score(Y_test, predict_model))\n",
        "    print('AUC Score:', roc_auc_score(Y_test, predict_model))\n",
        "    print('F1 Score:', f1_score(Y_test, predict_model))\n",
        "    print('Precision Score:', precision_score(Y_test, predict_model))\n",
        "    print('Recall Score:', recall_score(Y_test, predict_model))\n",
        "    print('\\n')\n",
        "#     print(classification_report(Y_test, predict_model))\n",
        "#     print('Confusion Matrix:', '\\n', pd.DataFrame(confusion_matrix(Y_test, predict_model)))\n",
        "    \n",
        "#     score_train = model.score(X_train, Y_train)\n",
        "#     score_test = model.score(X_test, Y_test)\n",
        "    \n",
        "#     print(score_train, score_test)\n",
        "    return (f1_score(Y_test, predict_model), model, X_train, Y_train, cv, groups)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ef2e79b",
      "metadata": {
        "id": "8ef2e79b"
      },
      "source": [
        "# MODEL PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2264982",
      "metadata": {
        "id": "f2264982"
      },
      "outputs": [],
      "source": [
        "def model_pca(df, model, model_name, featureCount, n_to_reach, SMOTEBool=False):\n",
        "    \n",
        "    print('PCA RESULTS')\n",
        "    df = pd.concat([df[df.columns[8:]], df[df.columns[6]]], ignore_index=True, axis=1)\n",
        "    i = df.shape[1] - (featureCount + 1)\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    df.iloc[:,1:-i], df.iloc[:,0], test_size=0.2, random_state=0)\n",
        "\n",
        "\n",
        "\n",
        "    param_grid = {}\n",
        "    pos_weight = sum(Y_train[Y_train == 0]) / sum(Y_train[Y_train == 1])\n",
        "    train_weight = sum(1 if x == 0 else 0 for x in Y_train)\\\n",
        "                        /sum(1 if x == 1 else 0 for x in Y_train)\n",
        "    # Parameter tuning\n",
        "    if model_name == 'lgb':\n",
        "        \n",
        "        param_grid = {\n",
        "#                     'max_depth': [2, 3, 4],\n",
        "#                     'num_leaves': [16,48,96],\n",
        "#                     'max_bin': [500,1000],\n",
        "#                     'boosting_type': ['dart'],\n",
        "#                     'learning_rate': [0.01,0.03],\n",
        "#                     'n_estimators' : [500,1000]\n",
        "                'boosting_type': ['gbdt', 'goss', 'dart'],\n",
        "                'num_leaves': list(range(10, 20)),\n",
        "                'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
        "                'num_iterations': list(range(50, 100)),\n",
        "                'early_stopping_rounds': list(range(1, 10)),\n",
        "                'scale_pos_weight': [pos_weight],\n",
        "                'max_depth':list(range(1,12)),\n",
        "                'max_bin': list(range(2, 30)),\n",
        "                'n_jobs' : [-1],\n",
        "                'path_smooth': list(range(2,15)),\n",
        "                'random_state': [0]\n",
        "                     }\n",
        "\n",
        "    \n",
        "    elif model_name == 'rfc':\n",
        "        \n",
        "        param_grid = {'bootstrap': [True],\n",
        "                       'max_depth': [2, 3, 4],\n",
        "                       'n_estimators': [100, 300, 500],\n",
        "                       'criterion' :['gini', 'entropy']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'SVM':\n",
        "        \n",
        "        param_grid = {'C': [0.01, 0.1, 1, 3, 5],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['linear']\n",
        "                     }\n",
        "        \n",
        "    \n",
        "    elif model_name == 'KNN':\n",
        "        \n",
        "        param_grid = {'n_neighbors': list(range(3,21)),\n",
        "              'metric': ['euclidean']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'XGB':\n",
        "        \n",
        "        \n",
        "        \n",
        "        param_grid = {'learning_rate':[0.01, 0.03, 0.05, 0.1],\n",
        "                'max_depth':[2,3,4],\n",
        "                'booster': ('gbtree', 'gblinear'),\n",
        "                'random_state': [0],\n",
        "                'n_jobs': [-1],\n",
        "                'scale_pos_weight': [pos_weight],\n",
        "                'gamma': [1, 5, 10],\n",
        "                'min_child_weight': list(range(3,8)),\n",
        "                'use_label_encoder': [False],\n",
        "                'early_stopping_rounds': list(range(3,10)),\n",
        "                'objective': ['binary:logistic'], \n",
        "                'eval_metric': ['auc'],\n",
        "                'verbosity': [0]\n",
        "                     }\n",
        "        \n",
        "       \n",
        "    # finding n_components for maintaining specified variance\n",
        "        # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    \n",
        "    # Normalization\n",
        "#     scaler = MinMaxScaler()\n",
        "    \n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "#     X_train_scaled = pd.DataFrame(X_train_scaled)\n",
        "#     X_train_scaled.index = X_train.index\n",
        "    \n",
        "    \n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "#     X_test_scaled = pd.DataFrame(X_test_scaled)\n",
        "#     X_test_scaled.index = X_test.index    \n",
        "    \n",
        "    print(\"Starting PCA...\")\n",
        "    start = time.time()\n",
        "    # pca = PCA()    \n",
        "    # X_pca_train = pca.fit_transform(X_train_scaled)\n",
        "    \n",
        "    # total_explained_variance = pca.explained_variance_ratio_.cumsum()\n",
        "    # n_over = len(total_explained_variance[total_explained_variance >= variance])\n",
        "    # n_to_reach = X_train.shape[1] - n_over + 1\n",
        "    # print(\"Number features: {}\\tTotal Variance Explained: {}\"\n",
        "    #       .format(n_to_reach, total_explained_variance[n_to_reach-1]))\n",
        "    \n",
        "    pca = PCA(n_components=n_to_reach)    \n",
        "    X_pca_train = pca.fit_transform(X_train_scaled)\n",
        "    X_pca_train = pd.DataFrame(X_pca_train)\n",
        "    X_pca_train.index = X_train.index\n",
        "    X_pca_train = pd.merge(X_pca_train, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_pca_train.columns = np.arange(X_pca_train.shape[1]) \n",
        "\n",
        "    X_pca_test = pca.transform(X_test_scaled)\n",
        "    X_pca_test = pd.DataFrame(X_pca_test)\n",
        "    X_pca_test.index = X_test.index\n",
        "    X_pca_test = pd.merge(X_pca_test, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_pca_test.columns = np.arange(X_pca_test.shape[1])\n",
        "    X_pca_test = X_pca_test.iloc[:,:-1]\n",
        "    \n",
        "    groups = X_pca_train.iloc[:,-1]\n",
        "    X_pca_train = X_pca_train.iloc[:,:-1]\n",
        "    end = time.time()\n",
        "    print(f\"Total Time of PCA = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "\n",
        "    #SMOTE for Train Data to Balance Dataset and also to Increase Data Size\n",
        "    if SMOTEBool == True:\n",
        "        oversample = SMOTE()\n",
        "        X_pca_train, Y_train = oversample.fit_resample(X_pca_train, Y_train)\n",
        "    \n",
        "    # K-fold cross validation\n",
        "    cv = StratifiedGroupKFold(n_splits=5, random_state=1, shuffle=True)\n",
        "#     cv_results = cross_val_score(model, X_pca_train, Y_train, groups=groups, cv=cv, scoring='accuracy')\n",
        "#     print('Cross Validation Accuracy: %.3f (%.3f)' % (np.mean(cv_results), np.std(cv_results)))\n",
        "        \n",
        "    # GridSearch for Hyperparameters\n",
        "    model_ = GridSearchCV(model,           # model\n",
        "              param_grid = param_grid,    # hyperparameters\n",
        "              scoring='accuracy',         # metric for scoring\n",
        "              cv=cv,                      # number of folds\n",
        "              n_jobs=-1)\n",
        "    print(\"Starting fitting into the model...\")\n",
        "    start = time.time()          \n",
        "    model_.fit(X_pca_train,Y_train, groups=groups)\n",
        "    end = time.time()\n",
        "    print(f\"Total Time of model fit = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "\n",
        "    \n",
        "    model.set_params(**model_.best_params_)\n",
        "    print(model.get_params())\n",
        "    #permutationTest(model, X_pca_train, Y_train, cv, groups)\n",
        "    \n",
        "#     # perform permutation importance\n",
        "#     results = permutation_importance(model_, X_pca_train, Y_train, scoring='accuracy')\n",
        "#     # get importance\n",
        "#     importance = results.importances_mean\n",
        "#     # summarize feature importance\n",
        "#     for i,v in enumerate(importance):\n",
        "#         print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "#     # plot feature importance\n",
        "#     plt.bar([x for x in range(len(importance))], importance)\n",
        "#     plt.show()\n",
        "    \n",
        "    \n",
        "    print(\"Tuned Hyperparameters :\", model_.best_params_)\n",
        "#     print(\"Tuned Best Accuracy :\", model_.best_score_)\n",
        "    \n",
        "    # Predictions\n",
        "    pred_prob = model_.predict_proba(X_pca_test)\n",
        "#     print(pred_prob)\n",
        "\n",
        "    # keep probabilities for the positive outcome only\n",
        "    pred_prob = pred_prob[:, 1]\n",
        "#     print(pred_prob_pos)\n",
        "    \n",
        "    # calculate roc curves\n",
        "    fpr, tpr, thresholds = roc_curve(Y_test, pred_prob)\n",
        "    \n",
        "    # calculate the g-mean for each threshold\n",
        "    gmeans = np.sqrt(tpr * (1-fpr))\n",
        "    \n",
        "    # locate the index of the largest g-mean\n",
        "    ix = np.argmax(gmeans)\n",
        "#     print('Best Threshold = %f, G-Mean = %.3f' % (thresholds[ix], gmeans[ix]))\n",
        "    print('Train Accuracy Score:', model_.score(X_pca_train, Y_train))   \n",
        "\n",
        "    # Probability of predictions adjusted to new threshold\n",
        "    predict_model = [1 if y >= thresholds[ix] else 0 for y in pred_prob]\n",
        "    \n",
        "    # Original threshold\n",
        "#     predict_model = [1 if y >= 0.5 else 0 for y in pred_prob]\n",
        "#     print(predict_model)\n",
        "\n",
        "    \n",
        "    #print(predict_lgb)\n",
        "    print('Test Accuracy Score:', accuracy_score(Y_test, predict_model))\n",
        "    print('AUC Score:', roc_auc_score(Y_test, predict_model))\n",
        "    print('F1 Score:', f1_score(Y_test, predict_model))\n",
        "    print('Precision Score:', precision_score(Y_test, predict_model))\n",
        "    print('Recall Score:', recall_score(Y_test, predict_model))\n",
        "    print('\\n')\n",
        "#     print(classification_report(Y_test, predict_model))\n",
        "#     print('Confusion Matrix:', '\\n', pd.DataFrame(confusion_matrix(Y_test, predict_model)))\n",
        "    \n",
        "#     score_train = model.score(X_train, Y_train)\n",
        "#     score_test = model.score(X_test, Y_test)\n",
        "    \n",
        "#     print(score_train, score_test)\n",
        "    return (f1_score(Y_test, predict_model), model_, X_pca_train, Y_train, cv, groups)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c055397d",
      "metadata": {
        "id": "c055397d"
      },
      "source": [
        "# MODEL TSNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebdb80d2",
      "metadata": {
        "id": "ebdb80d2"
      },
      "outputs": [],
      "source": [
        "def model_t_sne(df, model, model_name, featureCount, n_to_reach, SMOTEBool=False):\n",
        "    \n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    print('TSNE RESULTS')\n",
        "     # Test/Train Split\n",
        "    df = pd.concat([df[df.columns[8:]], df[df.columns[6]]], ignore_index=True, axis=1)\n",
        "    i = df.shape[1] - (featureCount + 1)\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    df.iloc[:,1:-i], df.iloc[:,0], test_size=0.2, random_state=0)\n",
        "#     print(X_train)\n",
        "\n",
        "    # Normalization\n",
        "#     scaler = MinMaxScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # pca = PCA()    \n",
        "    # X_tsne_train = pca.fit_transform(X_train_scaled)\n",
        "\n",
        "    \n",
        "    # total_explained_variance = pca.explained_variance_ratio_.cumsum()\n",
        "    # n_over = len(total_explained_variance[total_explained_variance >= variance])\n",
        "    # n_to_reach = X_train.shape[1] - n_over + 1\n",
        "    # print(\"Number features: {}\\tTotal Variance Explained: {}\"\n",
        "    #       .format(n_to_reach, total_explained_variance[n_to_reach-1]))\n",
        "    \n",
        "    # T-SNE\n",
        "    print(\"Starting TSNE...\")\n",
        "    start = time.time()    \n",
        "    tsne = TSNE(n_components=n_to_reach, \n",
        "                init='pca', random_state=0, method='exact', n_jobs=-1, learning_rate = 0.1, n_iter=2000)\n",
        "    X_tsne_train = tsne.fit_transform(X_train_scaled)\n",
        "    X_tsne_train = pd.DataFrame(X_tsne_train)\n",
        "    X_tsne_train.index = X_train.index\n",
        "    X_tsne_train = pd.merge(X_tsne_train, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_tsne_train.columns = np.arange(X_tsne_train.shape[1]) \n",
        "\n",
        "\n",
        "    X_tsne_test = tsne.fit_transform(X_test_scaled)\n",
        "    X_tsne_test = pd.DataFrame(X_tsne_test)\n",
        "    X_tsne_test.index = X_test.index\n",
        "    X_tsne_test = pd.merge(X_tsne_test, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_tsne_test.columns = np.arange(X_tsne_test.shape[1])\n",
        "    X_tsne_test = X_tsne_test.iloc[:,:-1]\n",
        "    \n",
        "    groups = X_tsne_train.iloc[:,-1]\n",
        "    X_tsne_train = X_tsne_train.iloc[:,:-1]\n",
        "    end = time.time()\n",
        "    print(f\"Total Time of TSNE = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "    \n",
        "    #SMOTE for Train Data to Balance Dataset and also to Increase Data Size\n",
        "    if SMOTEBool == True:\n",
        "        oversample = SMOTE()\n",
        "        X_tsne_train, Y_train = oversample.fit_resample(X_tsne_train, Y_train)\n",
        "    \n",
        "    \n",
        "    param_grid = {}\n",
        "    pos_weight = sum(Y_train[Y_train == 0]) / sum(Y_train[Y_train == 1])\n",
        "    train_weight = sum(1 if x == 0 else 0 for x in Y_train)\\\n",
        "                        /sum(1 if x == 1 else 0 for x in Y_train)\n",
        "    # Parameter tuning\n",
        "    if model_name == 'lgb':\n",
        "        \n",
        "        param_grid = {\n",
        "#                     'max_depth': [2, 3, 4],\n",
        "#                     'num_leaves': [16,48,96],\n",
        "#                     'max_bin': [500,1000],\n",
        "#                     'boosting_type': ['dart'],\n",
        "#                     'learning_rate': [0.01,0.03],\n",
        "#                     'n_estimators' : [500,1000]\n",
        "                'boosting_type': ['gbdt', 'goss', 'dart'],\n",
        "                'num_leaves': list(range(10, 20)),\n",
        "                'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
        "                'num_iterations': list(range(50, 100)),\n",
        "                'early_stopping_rounds': list(range(1, 10)),\n",
        "                'scale_pos_weight': [pos_weight],\n",
        "                'max_depth':list(range(1,12)),\n",
        "                'max_bin': list(range(2, 30)),\n",
        "                'n_jobs' : [-1],\n",
        "                'path_smooth': list(range(2,15)),\n",
        "                'random_state': [0]\n",
        "                     }\n",
        "\n",
        "    \n",
        "    elif model_name == 'rfc':\n",
        "        \n",
        "        param_grid = {'bootstrap': [True],\n",
        "                       'max_depth': [2, 3, 4],\n",
        "                       'n_estimators': [100, 300, 500],\n",
        "                       'criterion' :['gini', 'entropy']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'SVM':\n",
        "        \n",
        "        param_grid = {'C': [0.01, 0.1, 1, 3, 5],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['linear']\n",
        "                     }\n",
        "        \n",
        "    \n",
        "    elif model_name == 'KNN':\n",
        "        \n",
        "        param_grid = {'n_neighbors': list(range(3,21)),\n",
        "              'metric': ['euclidean']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'XGB':\n",
        "        \n",
        "        \n",
        "        \n",
        "        param_grid = {'learning_rate':[0.01, 0.03, 0.05, 0.1],\n",
        "                'max_depth':[2,3,4],\n",
        "                'booster': ('gbtree', 'gblinear'),\n",
        "                'random_state': [0],\n",
        "                'n_jobs': [-1],\n",
        "                'scale_pos_weight': [pos_weight],\n",
        "                'gamma': [1, 5, 10],\n",
        "                'min_child_weight': list(range(3,8)),\n",
        "                'use_label_encoder': [False],\n",
        "                'early_stopping_rounds': list(range(3,10)),\n",
        "                'objective': ['binary:logistic'], \n",
        "                'eval_metric': ['auc'],\n",
        "                'verbosity': [0]\n",
        "                     }\n",
        "\n",
        "    # K-fold cross validation\n",
        "    # print('Starting StratifiedGroupKFold...')\n",
        "    cv = StratifiedGroupKFold(n_splits=5, random_state=1, shuffle=True)\n",
        "#     cv_results = cross_val_score(model, X_tsne_train, Y_train,groups=groups, cv=cv, scoring='accuracy')\n",
        "#     print('Cross Validation Accuracy: %.3f (%.3f)' % (np.mean(cv_results), np.std(cv_results)))\n",
        "    \n",
        "#     permutationTest(model, X_tsne_train, Y_train, cv, groups)\n",
        "    \n",
        "    # GridSearch for Hyperparameters\n",
        "    print(\"Starting fitting into the model...\")\n",
        "    start = time.time()\n",
        "    model_ = GridSearchCV(model,           # model\n",
        "              param_grid = param_grid,    # hyperparameters\n",
        "              scoring='accuracy',         # metric for scoring\n",
        "              cv=cv,                    # number of folds\n",
        "              n_jobs=-1)             \n",
        "    model_.fit(X_tsne_train,Y_train, groups=groups)\n",
        "    end = time.time()\n",
        "    print(f\"Total Time of model fit = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "    \n",
        "#     # perform permutation importance\n",
        "#     results = permutation_importance(model_, X_tsne_train, Y_train, scoring='accuracy')\n",
        "#     # get importance\n",
        "#     importance = results.importances_mean\n",
        "#     # summarize feature importance\n",
        "#     for i,v in enumerate(importance):\n",
        "#         print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "#     # plot feature importance\n",
        "#     plt.bar([x for x in range(len(importance))], importance)\n",
        "#     plt.show()\n",
        "    \n",
        "    \n",
        "    print(\"Tuned Hyperparameters :\", model_.best_params_)\n",
        "    \n",
        "    model.set_params(**model_.best_params_)\n",
        "    print(model.get_params())\n",
        "    \n",
        "    #permutationTest(model, X_tsne_train, Y_train, cv, groups)\n",
        "    \n",
        "#     print(\"Tuned Best Accuracy :\", model_.best_score_)\n",
        "    \n",
        "    # Predictions\n",
        "    pred_prob = model_.predict_proba(X_tsne_test)\n",
        "#     print(pred_prob)\n",
        "\n",
        "    # keep probabilities for the positive outcome only\n",
        "    pred_prob = pred_prob[:, 1]\n",
        "#     print(pred_prob_pos)\n",
        "    \n",
        "    # calculate roc curves\n",
        "    fpr, tpr, thresholds = roc_curve(Y_test, pred_prob)\n",
        "    \n",
        "    # calculate the g-mean for each threshold\n",
        "    gmeans = np.sqrt(tpr * (1-fpr))\n",
        "    \n",
        "    # locate the index of the largest g-mean\n",
        "    ix = np.argmax(gmeans)\n",
        "#     print('Best Threshold = %f, G-Mean = %.3f' % (thresholds[ix], gmeans[ix]))\n",
        "    print('Train Accuracy Score:', model_.score(X_tsne_train, Y_train))\n",
        "\n",
        "    # Probability of predictions adjusted to new threshold\n",
        "    predict_model = [1 if y >= thresholds[ix] else 0 for y in pred_prob]\n",
        "    \n",
        "    # Original threshold\n",
        "#     predict_model = [1 if y >= 0.5 else 0 for y in pred_prob]\n",
        "#     print(predict_model)\n",
        "\n",
        "    \n",
        "    #print(predict_lgb)\n",
        "    print('Test Accuracy Score:', accuracy_score(Y_test, predict_model))\n",
        "    print('AUC Score:', roc_auc_score(Y_test, predict_model))\n",
        "    print('F1 Score:', f1_score(Y_test, predict_model))\n",
        "    print('Precision Score:', precision_score(Y_test, predict_model))\n",
        "    print('Recall Score:', recall_score(Y_test, predict_model))\n",
        "    print('\\n')\n",
        "#     print(classification_report(Y_test, predict_model))\n",
        "#     print('Confusion Matrix:', '\\n', pd.DataFrame(confusion_matrix(Y_test, predict_model)))\n",
        "    \n",
        "#     score_train = model.score(X_train, Y_train)\n",
        "#     score_test = model.score(X_test, Y_test)\n",
        "    \n",
        "#     print(score_train, score_test)\n",
        "    return (f1_score(Y_test, predict_model), model_, X_tsne_train,Y_train, cv, groups)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a138064f",
      "metadata": {
        "id": "a138064f"
      },
      "source": [
        "# MODEL ISOMAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "801ae2b5",
      "metadata": {
        "id": "801ae2b5"
      },
      "outputs": [],
      "source": [
        "def model_isomap(df, model, model_name, featureCount, n_to_reach, SMOTEBool=False):\n",
        "    \n",
        "    df = pd.concat([df[df.columns[8:]], df[df.columns[6]]], ignore_index=True, axis=1)\n",
        "    i = df.shape[1] - (featureCount + 1)\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    df.iloc[:,1:-i], df.iloc[:,0], test_size=0.2, random_state=0)\n",
        "\n",
        "    print('ISOMAP RESULTS')\n",
        "\n",
        "    \n",
        "\n",
        "    param_grid = {}\n",
        "    pos_weight = sum(Y_train[Y_train == 0]) / sum(Y_train[Y_train == 1])\n",
        "    train_weight = sum(1 if x == 0 else 0 for x in Y_train)\\\n",
        "                        /sum(1 if x == 1 else 0 for x in Y_train)\n",
        "    # Parameter tuning\n",
        "    if model_name == 'lgb':\n",
        "        \n",
        "        param_grid = {\n",
        "#                     'max_depth': [2, 3, 4],\n",
        "#                     'num_leaves': [16,48,96],\n",
        "#                     'max_bin': [500,1000],\n",
        "#                     'boosting_type': ['dart'],\n",
        "#                     'learning_rate': [0.01,0.03],\n",
        "#                     'n_estimators' : [500,1000]\n",
        "                'boosting_type': ['gbdt', 'goss', 'dart'],\n",
        "                'num_leaves': list(range(10, 20)),\n",
        "                'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
        "                'num_iterations': list(range(50, 100)),\n",
        "                'early_stopping_rounds': list(range(1, 10)),\n",
        "                'scale_pos_weight': [pos_weight],\n",
        "                'max_depth':list(range(1,12)),\n",
        "                'max_bin': list(range(2, 30)),\n",
        "                'n_jobs' : [-1],\n",
        "                'path_smooth': list(range(2,15)),\n",
        "                'random_state': [0]\n",
        "                     }\n",
        "\n",
        "    \n",
        "    elif model_name == 'rfc':\n",
        "        \n",
        "        param_grid = {'bootstrap': [True],\n",
        "                       'max_depth': [2, 3, 4],\n",
        "                       'n_estimators': [100, 300, 500],\n",
        "                       'criterion' :['gini', 'entropy']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'SVM':\n",
        "        \n",
        "        param_grid = {'C': [0.01, 0.1, 1, 3, 5],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['linear']\n",
        "                     }\n",
        "        \n",
        "    \n",
        "    elif model_name == 'KNN':\n",
        "        \n",
        "        param_grid = {'n_neighbors': list(range(3,21)),\n",
        "              'metric': ['euclidean']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'XGB':\n",
        "        \n",
        "        \n",
        "        \n",
        "        param_grid = {'learning_rate':[0.01, 0.03, 0.05, 0.1],\n",
        "                'max_depth':[2,3,4],\n",
        "                'booster': ('gbtree', 'gblinear'),\n",
        "                'random_state': [0],\n",
        "                'n_jobs': [-1],\n",
        "                'scale_pos_weight': [pos_weight],\n",
        "                'gamma': [1, 5, 10],\n",
        "                'min_child_weight': list(range(3,8)),\n",
        "                'use_label_encoder': [False],\n",
        "                'early_stopping_rounds': list(range(3,10)),\n",
        "                'objective': ['binary:logistic'], \n",
        "                'eval_metric': ['auc'],\n",
        "                'verbosity': [0]\n",
        "                     }\n",
        "        \n",
        "    \n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    \n",
        "    # Normalization\n",
        "#     scaler = MinMaxScaler()\n",
        "\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    # pca = PCA()    \n",
        "    # X_iso_train = pca.fit_transform(X_train_scaled)\n",
        "    \n",
        "    # total_explained_variance = pca.explained_variance_ratio_.cumsum()\n",
        "    # n_over = len(total_explained_variance[total_explained_variance >= variance])\n",
        "    # n_to_reach = X_train.shape[1] - n_over + 1\n",
        "    # print(\"Number features: {}\\tTotal Variance Explained: {}\"\n",
        "    #       .format(n_to_reach, total_explained_variance[n_to_reach-1]))\n",
        "    \n",
        "    print(\"Starting ISOMAP...\")\n",
        "    start = time.time()\n",
        "    iso = Isomap(n_components=n_to_reach)    \n",
        "    X_iso_train = iso.fit_transform(X_train_scaled)\n",
        "    X_iso_train = pd.DataFrame(X_iso_train)\n",
        "    X_iso_train.index = X_train.index\n",
        "    X_iso_train = pd.merge(X_iso_train, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_iso_train.columns = np.arange(X_iso_train.shape[1]) \n",
        "\n",
        "\n",
        "    X_iso_test = iso.transform(X_test_scaled)\n",
        "    X_iso_test = pd.DataFrame(X_iso_test)\n",
        "    X_iso_test.index = X_test.index\n",
        "    X_iso_test = pd.merge(X_iso_test, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_iso_test.columns = np.arange(X_iso_test.shape[1])\n",
        "    X_iso_test = X_iso_test.iloc[:,:-1]\n",
        "    \n",
        "    groups = X_iso_train.iloc[:,-1]\n",
        "    X_iso_train = X_iso_train.iloc[:,:-1]\n",
        "    end = time.time()\n",
        "    print(f\"Total Time of ISOMAP = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "\n",
        "    #SMOTE for Train Data to Balance Dataset and also to Increase Data Size\n",
        "    if SMOTEBool == True:\n",
        "        oversample = SMOTE()\n",
        "        X_iso_train, Y_train = oversample.fit_resample(X_iso_train, Y_train)\n",
        "    \n",
        "    # K-fold cross validation\n",
        "    # print('Starting StratifiedGroupKFold...')\n",
        "    cv = StratifiedGroupKFold(n_splits=5, random_state=1, shuffle=True)\n",
        "#     cv_results = cross_val_score(model, X_iso_train, Y_train, groups=groups, cv=cv, scoring='accuracy')\n",
        "#     print('Cross Validation Accuracy: %.3f (%.3f)' % (np.mean(cv_results), np.std(cv_results)))\n",
        "    \n",
        "#     permutationTest(model, X_iso_train, Y_train, cv, groups)\n",
        "    \n",
        "    # GridSearch for Hyperparameters\n",
        "    print(\"Starting fitting into the model...\")\n",
        "    start = time.time()\n",
        "    model_ = GridSearchCV(model,           # model\n",
        "              param_grid = param_grid,    # hyperparameters\n",
        "              scoring='accuracy',         # metric for scoring\n",
        "              cv=cv,                      # number of folds\n",
        "              n_jobs=-1)             \n",
        "    model_.fit(X_iso_train,Y_train, groups=groups)\n",
        "    end = time.time()\n",
        "    print(f\"Total Time of model fit = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "\n",
        "\n",
        "    model.set_params(**model_.best_params_)\n",
        "    print(model.get_params())\n",
        "    \n",
        "    #permutationTest(model, X_iso_train, Y_train, cv, groups)\n",
        "    \n",
        "#     # perform permutation importance\n",
        "#     results = permutation_importance(model_, X_iso_train, Y_train, scoring='accuracy')\n",
        "#     # get importance\n",
        "#     importance = results.importances_mean\n",
        "#     # summarize feature importance\n",
        "#     for i,v in enumerate(importance):\n",
        "#         print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "#     # plot feature importance\n",
        "#     plt.bar([x for x in range(len(importance))], importance)\n",
        "#     plt.show()\n",
        "    \n",
        "    \n",
        "    print(\"Tuned Hyperparameters :\", model_.best_params_)\n",
        "#     print(\"Tuned Best Accuracy :\", model_.best_score_)\n",
        "    \n",
        "    # Predictions\n",
        "    pred_prob = model_.predict_proba(X_iso_test)\n",
        "#     print(pred_prob)\n",
        "\n",
        "    # keep probabilities for the positive outcome only\n",
        "    pred_prob = pred_prob[:, 1]\n",
        "#     print(pred_prob_pos)\n",
        "    \n",
        "    # calculate roc curves\n",
        "    fpr, tpr, thresholds = roc_curve(Y_test, pred_prob)\n",
        "    \n",
        "    # calculate the g-mean for each threshold\n",
        "    gmeans = np.sqrt(tpr * (1-fpr))\n",
        "    \n",
        "    # locate the index of the largest g-mean\n",
        "    ix = np.argmax(gmeans)\n",
        "#     print('Best Threshold = %f, G-Mean = %.3f' % (thresholds[ix], gmeans[ix]))\n",
        "    print('Train Accuracy Score:', model_.score(X_iso_train, Y_train))   \n",
        "  \n",
        "    # Probability of predictions adjusted to new threshold\n",
        "    predict_model = [1 if y >= thresholds[ix] else 0 for y in pred_prob]\n",
        "    \n",
        "    # Original threshold\n",
        "#     predict_model = [1 if y >= 0.5 else 0 for y in pred_prob]\n",
        "#     print(predict_model)\n",
        "\n",
        "    \n",
        "    #print(predict_lgb)\n",
        "    print('Test Accuracy Score:', accuracy_score(Y_test, predict_model))\n",
        "    print('AUC Score:', roc_auc_score(Y_test, predict_model))\n",
        "    print('F1 Score:', f1_score(Y_test, predict_model))\n",
        "    print('Precision Score:', precision_score(Y_test, predict_model))\n",
        "    print('Recall Score:', recall_score(Y_test, predict_model))\n",
        "    print('\\n')\n",
        "#     print(classification_report(Y_test, predict_model))\n",
        "#     print('Confusion Matrix:', '\\n', pd.DataFrame(confusion_matrix(Y_test, predict_model)))\n",
        "    \n",
        "#     score_train = model.score(X_train, Y_train)\n",
        "#     score_test = model.score(X_test, Y_test)\n",
        "    \n",
        "#     print(score_train, score_test)\n",
        "    return (f1_score(Y_test, predict_model), model_, X_iso_train, Y_train, cv, groups)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a237fda6",
      "metadata": {
        "id": "a237fda6"
      },
      "outputs": [],
      "source": [
        "def main_model_WithinEachIndividual(df, model, model_name, featureCount, SMOTEBool=False):\n",
        "    \n",
        " \n",
        "    df = pd.concat([df[df.columns[8:]], df[df.columns[6]]], ignore_index=True, axis=1)\n",
        "    i = df.shape[1] - (featureCount + 1)\n",
        "    print(i)\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    df.iloc[:,1:-i], df.iloc[:,0], test_size=0.20, random_state=0)\n",
        "    print('MAIN RESULTS')\n",
        "    \n",
        "    param_grid = {}\n",
        "    \n",
        "    # Parameter tuning\n",
        "    if model_name == 'lgb':\n",
        "        \n",
        "        train_weight = sum(1 if x == 0 else 0 for x in Y_train)\\\n",
        "                        /sum(1 if x == 1 else 0 for x in Y_train)\n",
        "\n",
        "        param_grid = {'max_depth': [2, 3, 4],\n",
        "                    'num_leaves': [16,48,96],\n",
        "                    'max_bin': [500,1000],\n",
        "                    'boosting_type': ['dart'],\n",
        "                    'learning_rate': [0.01,0.03],\n",
        "                    'n_estimators' : [500,1000]\n",
        "                     }\n",
        "    \n",
        "    elif model_name == 'rfc':\n",
        "        \n",
        "        param_grid = {'bootstrap': [True],\n",
        "                       'max_depth': [2, 3, 4],\n",
        "                       'n_estimators': [100, 300, 500],\n",
        "                       'criterion' :['gini', 'entropy']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'SVM':\n",
        "        \n",
        "        param_grid = {'C': [0.01, 0.1, 1, 3, 5],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['linear']\n",
        "                     }\n",
        "        \n",
        "    \n",
        "    elif model_name == 'KNN':\n",
        "        \n",
        "        param_grid = {'n_neighbors': list(range(3,21)),\n",
        "              'metric': ['euclidean']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'XGB':\n",
        "        \n",
        "        param_grid = {'learning_rate':[0.01, 0.03, 0.05, 0.1],\n",
        "                'max_depth':[2,3,4],\n",
        "                'booster': ('gbtree', 'gblinear'),\n",
        "                'random_state': [0],\n",
        "                'n_jobs': [-1],\n",
        "                'gamma': [1, 5, 10],\n",
        "                'min_child_weight': list(range(3,8)),\n",
        "                'use_label_encoder': [False],\n",
        "                'objective': ['binary:logistic'], \n",
        "                'eval_metric': ['error'],\n",
        "                'verbosity': [0]\n",
        "                     } \n",
        "        \n",
        "        \n",
        "        \n",
        "       \n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    \n",
        "    # Normalization\n",
        "#     scaler = MinMaxScaler()\n",
        "    \n",
        "    \n",
        "    # Pipeline\n",
        "#     pipe = Pipeline([('scaler', scaler),\n",
        "#                      ('clf', model)])\n",
        "\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_train_scaled = pd.DataFrame(X_train_scaled)\n",
        "    X_train_scaled.index = X_train.index\n",
        "    X_train = pd.merge(X_train_scaled, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_train.columns = np.arange(X_train.shape[1])\n",
        "    \n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    X_test_scaled = pd.DataFrame(X_test_scaled)\n",
        "    X_test_scaled.index = X_test.index\n",
        "    X_test = pd.merge(X_test_scaled, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_test.columns = np.arange(X_test.shape[1])\n",
        "    X_test = X_test.iloc[:,:-1]\n",
        "    \n",
        "    groups = X_train.iloc[:,-1]\n",
        "    X_train = X_train.iloc[:,:-1]\n",
        "    \n",
        "    if SMOTEBool == True:\n",
        "        oversample = SMOTE()\n",
        "        X_train, Y_train = oversample.fit_resample(X_train, Y_train)\n",
        "    \n",
        "    # K-fold cross validation\n",
        "    cv = StratifiedGroupKFold(n_splits=5, random_state=1, shuffle=True)\n",
        "#     cv_results = cross_val_score(model, X_train, Y_train, groups=groups, cv=cv, scoring='accuracy')\n",
        "#     print('Cross Validation Accuracy: %.3f (%.3f)' % (np.mean(cv_results), np.std(cv_results)))\n",
        "    \n",
        "    \n",
        "#     permutationTest(model, X_train, Y_train, cv, groups)\n",
        "       \n",
        "    \n",
        "    # Randomized Search for Hyperparameters\n",
        "#     model_ = RandomizedSearchCV(pipe, param_grid, scoring='accuracy',cv=cv, random_state=0)\n",
        "#     model_.fit(X_train,Y_train)\n",
        "    \n",
        "    # GridSearch for Hyperparameters\n",
        "    \n",
        "    model_ = GridSearchCV(model,           # model\n",
        "              param_grid = param_grid,    # hyperparameters\n",
        "              scoring='accuracy',         # metric for scoring\n",
        "              cv=cv                      # number of folds\n",
        "              )             \n",
        "    model_.fit(X_train, Y_train, groups=groups)\n",
        "    \n",
        "    model.set_params(**model_.best_params_)\n",
        "    print(model.get_params())\n",
        "    permutationTest(model, X_train, Y_train, cv, groups)\n",
        "    \n",
        "#     # perform permutation importance\n",
        "#     results = permutation_importance(model_, X_train, Y_train, scoring='accuracy')\n",
        "#     # get importance\n",
        "#     importance = results.importances_mean\n",
        "#     # summarize feature importance\n",
        "#     for i,v in enumerate(importance):\n",
        "#         print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "#     # plot feature importance\n",
        "#     plt.bar([x for x in range(len(importance))], importance)\n",
        "#     plt.show()\n",
        "    \n",
        "    print(\"Tuned Hyperparameters :\", model_.best_params_)\n",
        "#     print(\"Tuned Best Accuracy :\", model_.best_score_)\n",
        "    \n",
        "    # Predictions\n",
        "    pred_prob = model_.predict_proba(X_test)\n",
        "#     print(pred_prob)\n",
        "\n",
        "    # keep probabilities for the positive outcome only\n",
        "    pred_prob = pred_prob[:, 1]\n",
        "#     print(pred_prob_pos)\n",
        "    \n",
        "    # calculate roc curves\n",
        "    fpr, tpr, thresholds = roc_curve(Y_test, pred_prob)\n",
        "    \n",
        "    # calculate the g-mean for each threshold\n",
        "    gmeans = np.sqrt(tpr * (1-fpr))\n",
        "    \n",
        "    # locate the index of the largest g-mean\n",
        "    ix = np.argmax(gmeans)\n",
        "#     print('Best Threshold = %f, G-Mean = %.3f' % (thresholds[ix], gmeans[ix]))\n",
        "    print('Train Accuracy Score:', model_.score(X_train, Y_train))   \n",
        "    \n",
        "    # Probability of predictions adjusted to new threshold\n",
        "    predict_model = [1 if y >= thresholds[ix] else 0 for y in pred_prob]\n",
        "    \n",
        "    # Original threshold\n",
        "#     predict_model = [1 if y >= 0.5 else 0 for y in pred_prob]\n",
        "#     print(predict_model)\n",
        "\n",
        "    \n",
        "    #print(predict_lgb)\n",
        "    print('Test Accuracy Score:', accuracy_score(Y_test, predict_model))\n",
        "    print('AUC Score:', roc_auc_score(Y_test, predict_model))\n",
        "    print('F1 Score:', f1_score(Y_test, predict_model))\n",
        "    print('Precision Score:', precision_score(Y_test, predict_model))\n",
        "    print('Recall Score:', recall_score(Y_test, predict_model))\n",
        "    print('\\n')\n",
        "#     print(classification_report(Y_test, predict_model))\n",
        "#     print('Confusion Matrix:', '\\n', pd.DataFrame(confusion_matrix(Y_test, predict_model)))\n",
        "    \n",
        "#     score_train = model.score(X_train, Y_train)\n",
        "#     score_test = model.score(X_test, Y_test)\n",
        "    \n",
        "#     print(score_train, score_test)\n",
        "    return f1_score(Y_test, predict_model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "307.194px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4YTOPv6EuIEu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YTOPv6EuIEu",
        "outputId": "5368c598-b353-4158-eb36-5782d2421b4c",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting impyute\n",
            "  Downloading impyute-0.0.8-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from impyute) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from impyute) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from impyute) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->impyute) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->impyute) (1.1.0)\n",
            "Installing collected packages: impyute\n",
            "Successfully installed impyute-0.0.8\n"
          ]
        }
      ],
      "source": [
        "!pip install impyute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46ed5885",
      "metadata": {
        "id": "46ed5885",
        "scrolled": false,
        "outputId": "9db4c8e0-c52e-4e0a-9a75-cac48b2a4e96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/avalanche/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
            "  from pandas import MultiIndex, Int64Index\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import math\n",
        "from collections import defaultdict\n",
        "from scipy.stats import spearmanr\n",
        "from scipy.cluster import hierarchy\n",
        "from scipy.spatial.distance import squareform\n",
        "\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from impyute.imputation.cs import mice\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import (train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, \n",
        "RepeatedStratifiedKFold, StratifiedKFold)\n",
        "from sklearn.model_selection import StratifiedGroupKFold, GroupShuffleSplit, permutation_test_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE, Isomap\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, scale\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, accuracy_score,roc_curve, f1_score, precision_score, recall_score, silhouette_score\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "\n",
        "# import datawig\n",
        "# Machine Learning Algorithms\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "\n",
        "import lightgbm as lgb\n",
        "from sklearn import tree\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture as GMM\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "\n",
        "#pd.options.display.max_rows = 999\n",
        "pd.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aed9f3df",
      "metadata": {
        "id": "aed9f3df"
      },
      "source": [
        "# Imputation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a12b848",
      "metadata": {
        "id": "3a12b848"
      },
      "outputs": [],
      "source": [
        "def mice_imputation(df_cleaned):\n",
        "    \n",
        "    #Preparing measurement values by putting them into new df to impute them later\n",
        "    X = df_cleaned[df_cleaned.columns[8:]]\n",
        "\n",
        "    imputed = mice(X.values,)\n",
        "    df_mice = pd.DataFrame(imputed)\n",
        "    \n",
        "    # Merging non-measurement features with non-outlier dataframe\n",
        "    #df_mice.columns = df_cleaned.columns[9:]\n",
        "    df_mice = pd.concat([df_cleaned[df_cleaned.columns[:8]], df_mice], ignore_index=True, axis=1)\n",
        "    df_mice.columns = df_cleaned.columns\n",
        "    return df_mice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffe2991b",
      "metadata": {
        "id": "ffe2991b"
      },
      "outputs": [],
      "source": [
        "def iter_imputation(df_cleaned,estimator=BayesianRidge(), max_iter=10,iter_verbose=0,verbose=False):\n",
        "    df_cleaned.reset_index(drop=True,inplace=True)\n",
        "    data_iter =  df_cleaned.iloc[:,9:]\n",
        "    # print total missing\n",
        "    if verbose:\n",
        "        print('Missing: %d' % df_cleaned.isnull().sum().sum())\n",
        "    # define imputer\n",
        "    imputer = IterativeImputer(n_nearest_features=3, \n",
        "                               imputation_order='ascending', \n",
        "                               verbose=iter_verbose,\n",
        "                               max_iter=max_iter,\n",
        "                              estimator=estimator)\n",
        "\n",
        "    # fit and transform the dataset\n",
        "    Xtrans = imputer.fit_transform(data_iter)\n",
        "    # print total missing\n",
        "    if verbose:\n",
        "        print('Missing: %d' % np.count_nonzero(np.isnan(Xtrans)))\n",
        "    \n",
        "    # Merging non-measurement features with filled measurement into df\n",
        "\n",
        "    df_Xtrans= pd.DataFrame(Xtrans)             \n",
        "    df_iter_imputation = pd.concat([df_cleaned[df_cleaned.columns[:9]], df_Xtrans], ignore_index=True, axis=1)\n",
        "    df_iter_imputation.columns = df_cleaned.columns\n",
        "    \n",
        "    \n",
        "    return df_iter_imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bba6e75",
      "metadata": {
        "id": "7bba6e75"
      },
      "outputs": [],
      "source": [
        "# def iter_imputation(df_cleaned):\n",
        "    \n",
        "#     data_iter =  df_cleaned.drop(df_cleaned.iloc[:, 0:9], axis= 1)\n",
        "#     # split into input and output elements\n",
        "#     df_cleaned_values = data_iter.values\n",
        "#     ix = [i for i in range(data_iter.shape[1]) if i != 0 ]\n",
        "#     # X, y = df_cleaned_values[:, ix], df_cleaned_values[:, 0]\n",
        "#     X, y = df_cleaned_values, df_cleaned_values[:, 0]\n",
        "\n",
        "#     # print total missing\n",
        "#     print('Missing: %d' % df_cleaned.isnull().sum().sum())\n",
        "#     # define i,mputer\n",
        "#     imputer = IterativeImputer(estimator=BayesianRidge(), n_nearest_features=3, imputation_order='ascending',random_state=0)\n",
        "#     # fit on the dataset\n",
        "#     imputer.fit(X)\n",
        "#     # transform the dataset\n",
        "#     Xtrans = imputer.transform(X)\n",
        "#     # print total missing\n",
        "#     print('Missing: %d' % np.count_nonzero(np.isnan(Xtrans)))\n",
        "    \n",
        "#     # Merging non-measurement features with filled measurement into df\n",
        "\n",
        "#     df_Xtrans= pd.DataFrame(Xtrans)             \n",
        "#     df_iter_imputation = pd.concat([df_cleaned[df_cleaned.columns[:9]], df_Xtrans], ignore_index=True, axis=1)\n",
        "#     df_iter_imputation.columns = df_cleaned.columns\n",
        "    \n",
        "    \n",
        "#     return df_iter_imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17ef7956",
      "metadata": {
        "id": "17ef7956"
      },
      "outputs": [],
      "source": [
        "def iter_imputation_v2(df_out_notLike,estimator=BayesianRidge(),max_iter=10,iter_verbose=0,verbose=False):\n",
        "# Some participants' hemodynamic measurements, \n",
        "# e.g. Goxy15, is totally empty so we need to first impute first row of it with its neighbours\n",
        "# to not get eror in iterative imputation\n",
        "    if not verbose:\n",
        "        warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
        "    else:\n",
        "        warnings.filterwarnings(action='default', category=ConvergenceWarning)\n",
        "\n",
        "\n",
        "    part_no = df_out_notLike['Part_No'].drop_duplicates().to_list()\n",
        "    df_list = []\n",
        "    count = 1\n",
        "    for part in part_no:\n",
        "        if verbose:\n",
        "            print(f'Iteration: {count} Part_no:{part}')\n",
        "        df_temp = df_out_notLike[df_out_notLike['Part_No'] == part]\n",
        "        # assign a value to the first value of a column where it has all values as NaN\n",
        "        columns = df_temp.columns\n",
        "        for colName in columns:\n",
        "            if df_temp[colName].isna().sum() >= df_temp.shape[0]:\n",
        "\n",
        "                if colName[-2:] == '15' or colName[-2:] == '16':\n",
        "                    df_temp.iloc[0,columns.get_loc(colName)] = df_temp.iloc[0,columns.get_loc(colName)-2:columns.get_loc(colName)].mean()\n",
        "                    if math.isnan(df_temp.iloc[0,columns.get_loc(colName)]):\n",
        "                        df_temp.iloc[0,columns.get_loc(colName)] = df_temp.iloc[:,columns.get_loc(colName)-2:\n",
        "                                                                                columns.get_loc(colName)].mean().mean()\n",
        "                elif (int(colName[-1]) > 0 and int(colName[-1]) < 10) or (int(colName[-2:]) > 9 and int(colName[-2:]) < 14):\n",
        "                    df_temp.iloc[0,columns.get_loc(colName)] = df_temp.iloc[0,columns.get_loc(colName)+1:\n",
        "                                                                        columns.get_loc(colName)+3].mean()\n",
        "                    if math.isnan(df_temp.iloc[0,columns.get_loc(colName)]):\n",
        "                        df_temp.iloc[0,columns.get_loc(colName)] = df_temp.iloc[:,columns.get_loc(colName)+1:\n",
        "                                                                        columns.get_loc(colName)+5].mean().mean()\n",
        "                if verbose:\n",
        "                    print(f'ColName={colName} and ParticipantNo={part}')\n",
        "\n",
        "\n",
        "\n",
        "        df_temp = iter_imputation(df_temp.reset_index(drop=True),\n",
        "                                  estimator=estimator,\n",
        "                                  max_iter=max_iter,\n",
        "                                  iter_verbose=iter_verbose,\n",
        "                                  verbose=verbose)\n",
        "        df_list.append(df_temp)\n",
        "        count += 1\n",
        "    df_temp_2 = df_list.pop(0)\n",
        "    for part in df_list:\n",
        "        df_temp_2 = pd.concat([df_temp_2,part])\n",
        "    df_temp_2 = df_temp_2.reset_index(drop=True)\n",
        "    return df_temp_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "395b08d0",
      "metadata": {
        "id": "395b08d0"
      },
      "outputs": [],
      "source": [
        "def iter_imputation_v3(df_out_notLike, estimator=BayesianRidge(), max_iter=10, iter_verbose=0, verbose=False):\n",
        "# Some participants' hemodynamic measurements,\n",
        "# e.g. Goxy15, is totally empty so we need to first impute first row of it with its neighbours\n",
        "# to not get eror in iterative imputation\n",
        "    if not verbose:\n",
        "        warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
        "        pd.options.mode.chained_assignment = None\n",
        "    else:\n",
        "        warnings.filterwarnings(action='default', category=ConvergenceWarning)\n",
        "        pd.options.mode.chained_assignment = 'warn'\n",
        "\n",
        "    part_no = df_out_notLike['Part_No'].drop_duplicates().to_list()\n",
        "    df_list = []\n",
        "    count = 1\n",
        "    for part in part_no:\n",
        "        if verbose:\n",
        "            print(f'Iteration: {count} Part_no:{part}')\n",
        "        df_temp = df_out_notLike.loc[df_out_notLike['Part_No'] == part]\n",
        "        # assign a value to the first value of a column where it has all values as NaN\n",
        "        columns = df_temp.columns\n",
        "        for colName in columns:\n",
        "            if df_temp[colName].isna().sum() >= df_temp.shape[0]:\n",
        "\n",
        "                if colName[-2:] == '16' or colName[-1:] == '8':\n",
        "                    loc = columns.get_loc(colName)\n",
        "                    df_temp.loc[:, colName] = df_temp.loc[:,[columns[loc-1], columns[loc-2]]].mean(axis=1)\n",
        " \n",
        "                elif colName[-2:] == '15' or colName[-1:] == '7':\n",
        "                    loc = columns.get_loc(colName)\n",
        "                    df_temp.loc[:, colName] = df_temp.loc[:, [columns[loc+1], columns[loc-2]]].mean(axis=1)\n",
        "\n",
        "                elif any(colName[-2:] in s for s in ('11','12','13','14')):\n",
        "                    loc= columns.get_loc(colName)\n",
        "                    df_temp.loc[:, colName] = df_temp.loc[:, [columns[loc+2], columns[loc-2]]].mean(axis=1)\n",
        "\n",
        "                elif colName[-2:] == '10' or int(colName[-1:]) == 2:\n",
        "                    loc= columns.get_loc(colName)\n",
        "                    df_temp.loc[:, colName] = df_temp.loc[:, [columns[loc+2], columns[loc-1]]].mean(axis=1)\n",
        "\n",
        "                elif int(colName[-1:]) == 9 or int(colName[-1:]) == 1:\n",
        "                    loc= columns.get_loc(colName)\n",
        "                    df_temp.loc[:, colName] = df_temp.loc[:, [columns[loc+2], columns[loc+1]]].mean(axis=1)\n",
        "\n",
        "                elif int(colName[-1:]) >  2 and int(colName[-1:]) < 7:\n",
        "                    loc = columns.get_loc(colName)\n",
        "                    df_temp.loc[:, colName]= df_temp.loc[:, [columns[loc+2], columns[loc-2]]].mean(axis=1)\n",
        "\n",
        "       \n",
        "                if verbose:\n",
        "                    print(f'ColName={colName} and ParticipantNo={part}')\n",
        "\n",
        "\n",
        "\n",
        "        df_temp= iter_imputation(df_temp.reset_index(drop=True),\n",
        "                                  estimator=estimator,\n",
        "                                  max_iter=max_iter,\n",
        "                                  iter_verbose=iter_verbose,\n",
        "                                  verbose=verbose)\n",
        "        df_list.append(df_temp)\n",
        "        count += 1\n",
        "    df_temp_2= df_list.pop(0)\n",
        "    for part in df_list:\n",
        "        df_temp_2 = pd.concat([df_temp_2, part])\n",
        "    df_temp_2= df_temp_2.reset_index(drop=True)\n",
        "    pd.options.mode.chained_assignment = 'warn'\n",
        "    return df_temp_2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dab1def",
      "metadata": {
        "id": "1dab1def"
      },
      "source": [
        "# Outlier Count Per Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82e46451",
      "metadata": {
        "id": "82e46451"
      },
      "outputs": [],
      "source": [
        "def outlierCountbyFeature(df):\n",
        "    \n",
        "    Q1 = df[df.columns[9:]].quantile(0.25)\n",
        "    Q3 = df[df.columns[9:]].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    \n",
        "    df_last_mea = df[df.columns[9:]]\n",
        "    df_last_mea = df_last_mea.fillna(df_last_mea.mean())\n",
        "    outlier_matrix = ((df_last_mea < (Q1 - 1.5 * IQR)) | (df_last_mea > (Q3 + 1.5 * IQR)))\n",
        "    \n",
        "    outlier_count = outlier_matrix.sum(axis=0)\n",
        "    outlier_percent = 100 * outlier_matrix.sum(axis=0) / df_last_mea.shape[0]\n",
        "    \n",
        "    # Df\n",
        "    outlier_df = pd.concat([outlier_count, outlier_percent],\n",
        "                              axis=1)\n",
        "    \n",
        "    outlier_df_final = outlier_df.rename(\n",
        "        columns={0: 'Outlier Count', 1: '% of Total Values'})\n",
        "    \n",
        "    # Sort the table by percentage of outlier count descending\n",
        "    outlier_df_final = (outlier_df_final[\n",
        "        outlier_df_final.iloc[:, 1] != 0].sort_values(\n",
        "        '% of Total Values', ascending=False).round(1))\n",
        "    return outlier_df_final"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fEEdZNdz2FA-",
      "metadata": {
        "id": "fEEdZNdz2FA-"
      },
      "source": [
        "# Outlier Count Per Fow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "boJBZykt2ZT_",
      "metadata": {
        "id": "boJBZykt2ZT_"
      },
      "outputs": [],
      "source": [
        "def outlierCountbyRow(df):\n",
        "    \n",
        "    Q1 = df[df.columns[9:]].quantile(0.25)\n",
        "    Q3 = df[df.columns[9:]].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    \n",
        "    df_last_mea = df[df.columns[9:]]\n",
        "    df_last_mea = df_last_mea.fillna(df_last_mea.mean())\n",
        "    outlier_matrix = ((df_last_mea < (Q1 - 1.5 * IQR)) | (df_last_mea > (Q3 + 1.5 * IQR)))\n",
        "    outlier_count = outlier_matrix.sum(axis=1)\n",
        "    outlier_percent = 100 * outlier_matrix.sum(axis=1) / df_last_mea.shape[1]\n",
        "    \n",
        "    # Df\n",
        "\n",
        "    outlier_df = pd.concat([outlier_count, outlier_percent],\n",
        "                              axis=1)\n",
        "    \n",
        "    outlier_df_final = outlier_df.rename(\n",
        "        columns={0: 'Outlier Feature Count', 1: '% of Total Values'})\n",
        "    \n",
        "    # Sort the table by percentage of outlier count descending\n",
        "    outlier_df_final = (outlier_df_final[\n",
        "        outlier_df_final.iloc[:, 1] != 0].sort_values(\n",
        "        '% of Total Values', ascending=False).round(1))\n",
        "    return outlier_df_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NiAZx-332csx",
      "metadata": {
        "id": "NiAZx-332csx"
      },
      "outputs": [],
      "source": [
        "def outlierCountbyRow_and_Activity(df):\n",
        "    \n",
        "    Q1 = df[df.columns[9:]].quantile(0.25)\n",
        "    Q3 = df[df.columns[9:]].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    \n",
        "    df_last_mea = df[df.columns[9:]]\n",
        "    df_last_mea = df_last_mea.fillna(df_last_mea.mean())\n",
        "\n",
        "    outlier_matrix = ((df_last_mea < (Q1 - 1.5 * IQR)) | (df_last_mea > (Q3 + 1.5 * IQR)))\n",
        "    outlier_count = outlier_matrix.sum(axis=1)\n",
        "    outlier_percent = 100 * outlier_matrix.sum(axis=1) / df_last_mea.shape[1]\n",
        "\n",
        "    outlier_matrix_higherActivity = ((df_last_mea > (Q3 + 1.5 * IQR)))\n",
        "    outlier_count_higherActivity = outlier_matrix_higherActivity.sum(axis=1)\n",
        "    outlier_percent_higherActivity = 100 * outlier_matrix_higherActivity.sum(axis=1) / df_last_mea.shape[1]\n",
        "\n",
        "    outlier_matrix_lowerActivity = ((df_last_mea < (Q1 - 1.5 * IQR)))\n",
        "    outlier_count_lowerActivity = outlier_matrix_lowerActivity.sum(axis=1)\n",
        "    outlier_percent_lowerActivity = 100 * outlier_matrix_lowerActivity.sum(axis=1) / df_last_mea.shape[1]\n",
        "    \n",
        "    # Df\n",
        "    outlier_df_new = pd.concat([outlier_count_higherActivity,outlier_percent_higherActivity, outlier_count_lowerActivity, outlier_percent_lowerActivity, outlier_count, outlier_percent],\n",
        "                              axis=1)  \n",
        "    outlier_df_final = outlier_df_new.rename(\n",
        "        columns={0: 'Outlier Feature Count(Higher Activity)', 1: 'Higher% of Total Values', 2:'Outlier Feature Count(Lower Activity)', 3: 'Lower% of Total Values',4: 'Outlier Feature Count(All)',5: '% of Total Values'})\n",
        "    \n",
        "    # Sort the table by percentage of outlier count descending\n",
        "    outlier_df_final = (outlier_df_final[\n",
        "        outlier_df_final.iloc[:, 1] != 0].sort_values(\n",
        "        '% of Total Values', ascending=False).round(1))\n",
        "    return outlier_df_final"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5864cce",
      "metadata": {
        "id": "d5864cce"
      },
      "source": [
        "# Missing Values Per Row Indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "077d468c",
      "metadata": {
        "id": "077d468c"
      },
      "outputs": [],
      "source": [
        "def missingValuesRows(df):\n",
        "    # Total missing valuesfvgcvg\n",
        "    mis_val = df.isnull().sum(axis=1)\n",
        "\n",
        "    # Percentage of missing values\n",
        "    mis_val_percent = 100 * df.isnull().sum(axis=1) / df.shape[1]\n",
        "\n",
        "    # Make a table with the results\n",
        "    mis_val_table = pd.concat([mis_val, mis_val_percent],\n",
        "                              axis=1)\n",
        "\n",
        "    # Rename the columns\n",
        "    mis_val_table_ren_rows = mis_val_table.rename(\n",
        "        columns={0: 'Missing Values', 1: '% of Total Values'})\n",
        "\n",
        "    # Sort the table by percentage of missing descending\n",
        "    mis_val_table_ren_rows = (mis_val_table_ren_rows[\n",
        "        mis_val_table_ren_rows.iloc[:, 1] != 0].sort_values(\n",
        "        '% of Total Values', ascending=False).round(1))\n",
        "\n",
        "    # Print some summary information\n",
        "    print(\"Your selected dataframe has \" + str(df.shape[0]) + \" columns.\\n\"\n",
        "          \"There are \" + str(mis_val_table_ren_rows.shape[0]) +\n",
        "          \" columns that have missing values.\")\n",
        "\n",
        "    # Return the dataframe with missing information\n",
        "    return mis_val_table_ren_rows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4772c40d",
      "metadata": {
        "id": "4772c40d"
      },
      "source": [
        "# Missing Value Per Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cad8b63",
      "metadata": {
        "id": "7cad8b63"
      },
      "outputs": [],
      "source": [
        "def missing_values_table(df):\n",
        "    # Total missing values\n",
        "    mis_val = df.isnull().sum()\n",
        "\n",
        "    # Percentage of missing values\n",
        "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
        "\n",
        "    # Make a table with the results\n",
        "    mis_val_table = pd.concat([mis_val, mis_val_percent],\n",
        "                              axis=1)\n",
        "\n",
        "    # Rename the columns\n",
        "    mis_val_table_ren_columns = mis_val_table.rename(\n",
        "        columns={0: 'Missing Values', 1: '% of Total Values'})\n",
        "\n",
        "    # Sort the table by percentage of missing descending\n",
        "    mis_val_table_ren_columns = (mis_val_table_ren_columns[\n",
        "        mis_val_table_ren_columns.iloc[:, 0] != 0].sort_values(\n",
        "        '% of Total Values', ascending=False).round(1))\n",
        "\n",
        "    # Print some summary information\n",
        "    print(\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"\n",
        "          \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
        "          \" columns that have missing values.\")\n",
        "\n",
        "    # Return the dataframe with missing information\n",
        "    return mis_val_table_ren_columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd25c0f8",
      "metadata": {
        "id": "cd25c0f8"
      },
      "source": [
        "# Outlier Removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e8b54d3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-09T20:17:06.466205Z",
          "start_time": "2022-10-09T20:17:06.458855Z"
        },
        "id": "3e8b54d3"
      },
      "outputs": [],
      "source": [
        "def OutlierRemoval_OutlierCap_byParticipant(df_last, outliersbyRow=18, perc=15):\n",
        "    c = df_last.columns[9:]\n",
        "    participant = df_last['Part_No'].unique()\n",
        "    df_out_final=pd.DataFrame(columns=df_last.columns)\n",
        "    for i in participant:\n",
        "\n",
        "        Q1 = df_last.loc[df_last.Part_No == i][c].quantile(0.25)\n",
        "        Q3 = df_last.loc[df_last.Part_No == i][c].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "\n",
        "        df_last_mea = df_last.loc[df_last.Part_No == i][c]\n",
        "#         df_last_mea = df_last_mea.fillna(df_last_mea.mean())\n",
        "\n",
        "        outlier_matrix = ((df_last_mea < (Q1 - 1.5 * IQR)) |\n",
        "                          (df_last_mea > (Q3 + 1.5 * IQR)))\n",
        "    \n",
        "        # capping outliers\n",
        "        df_cap = cap_outliers(df_last.loc[df_last.Part_No == i])\n",
        "\n",
        "        perc_temp = 1\n",
        "        outliersbyRow_temp = 100\n",
        "        while perc_temp < perc:\n",
        "            out_count = (outlier_matrix.sum(axis=1) >= outliersbyRow_temp).sum()\n",
        "            perc_temp = (out_count/df_last_mea.shape[0]*100).round(1)\n",
        "            if perc_temp > perc:\n",
        "                outliersbyRow_temp+=1\n",
        "                out_count = (outlier_matrix.sum(axis=1) >= outliersbyRow_temp).sum()\n",
        "            else:\n",
        "                outliersbyRow_temp-=1\n",
        "        outliersbyRow=outliersbyRow_temp\n",
        "            \n",
        "\n",
        "        print(\n",
        "            f'{i}: Row count to be removed:{out_count}, Total Rows: {df_last_mea.shape[0]} Removing Percentage:{(out_count/df_last_mea.shape[0]*100).round(1)}%')\n",
        "\n",
        "        # Removing rows which have > outliersbyRow outlier count\n",
        "        df_cap = df_cap[outlier_matrix.sum(axis=1) < outliersbyRow]\n",
        "        \n",
        "        # add participant to final df\n",
        "        df_out_final = pd.concat([df_out_final,df_cap])\n",
        "             \n",
        "    df_out_final.reset_index(inplace=True,drop=True)\n",
        "    return df_out_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8723cb61",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-09T19:21:53.729452Z",
          "start_time": "2022-10-09T19:21:53.720957Z"
        },
        "id": "8723cb61"
      },
      "outputs": [],
      "source": [
        "def OutlierRemoval_OutlierCap(df_last, outliersbyRow=18, perc=15):\n",
        "    Q1 = df_last[df_last.columns[9:]].quantile(0.25)\n",
        "    Q3 = df_last[df_last.columns[9:]].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    df_last_mea = df_last[df_last.columns[9:]]\n",
        "#     df_last_mea = df_last_mea.fillna(df_last_mea.mean())\n",
        "    outlier_matrix = ((df_last_mea < (Q1 - 1.5 * IQR)) |\n",
        "                      (df_last_mea > (Q3 + 1.5 * IQR)))\n",
        "\n",
        "    # capping outliers\n",
        "    df_cap = cap_outliers(df_last)\n",
        "\n",
        "    perc_temp = 1\n",
        "    outliersbyRow_temp = 100\n",
        "    while perc_temp < perc:\n",
        "        out_count = (outlier_matrix.sum(axis=1) >= outliersbyRow_temp).sum()\n",
        "        perc_temp = (out_count/df_last_mea.shape[0]*100).round(1)\n",
        "        if perc_temp > perc:\n",
        "            outliersbyRow_temp += 1\n",
        "            out_count = (outlier_matrix.sum(axis=1)\n",
        "                         >= outliersbyRow_temp).sum()\n",
        "        else:\n",
        "            outliersbyRow_temp -= 1\n",
        "    outliersbyRow = outliersbyRow_temp\n",
        "\n",
        "#     out_count = (outlier_matrix.sum(axis=1) >= outliersbyRow).sum()\n",
        "    print(f'Row count to be removed:{out_count}, Total Rows: {df_last_mea.shape[0]}'\n",
        "          f'Removing Percentage:{(out_count/df_last_mea.shape[0]*100).round(1)}%')\n",
        "\n",
        "    # Removing outlier records\n",
        "    df_cap = df_cap[outlier_matrix.sum(axis=1) < outliersbyRow]\n",
        "\n",
        "    return df_cap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e512fcca",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-09T14:35:32.218450Z",
          "start_time": "2022-10-09T14:35:32.208368Z"
        },
        "id": "e512fcca"
      },
      "outputs": [],
      "source": [
        "def OutlierRemoval_OutlierTransformNan_byParticipant(df_last, outliersbyRow=18, perc=15):\n",
        "    first_c = df_last.columns[:9]\n",
        "    c = df_last.columns[9:]\n",
        "    participant = df_last['Part_No'].unique()\n",
        "    df_out_final=pd.DataFrame(columns=df_last.columns)\n",
        "    for i in participant:\n",
        "\n",
        "        Q1 = df_last.loc[df_last.Part_No == i][c].quantile(0.25)\n",
        "        Q3 = df_last.loc[df_last.Part_No == i][c].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "\n",
        "        df_last_mea = df_last.loc[df_last.Part_No == i][c]\n",
        "#         df_last_mea = df_last_mea.fillna(df_last_mea.mean())\n",
        "\n",
        "        outlier_matrix = ((df_last_mea < (Q1 - 1.5 * IQR)) |\n",
        "                          (df_last_mea > (Q3 + 1.5 * IQR)))\n",
        "\n",
        "        perc_temp = 1\n",
        "        outliersbyRow_temp = 100\n",
        "        while perc_temp < perc:\n",
        "            out_count = (outlier_matrix.sum(axis=1) >= outliersbyRow_temp).sum()\n",
        "            perc_temp = (out_count/df_last_mea.shape[0]*100).round(1)\n",
        "            if perc_temp > perc:\n",
        "                outliersbyRow_temp+=1\n",
        "                out_count = (outlier_matrix.sum(axis=1) >= outliersbyRow_temp).sum()\n",
        "            else:\n",
        "                outliersbyRow_temp-=1\n",
        "        outliersbyRow=outliersbyRow_temp\n",
        "            \n",
        "\n",
        "#         out_count = (outlier_matrix.sum(axis=1) >= outliersbyRow).sum()\n",
        "\n",
        "        print(\n",
        "            f'{i}: Row count to be removed:{out_count}, Total Rows: {df_last_mea.shape[0]} Removing Percentage:{(out_count/df_last_mea.shape[0]*100).round(1)}%')\n",
        "\n",
        "        # Removing rows which have > outliersbyRow outlier count\n",
        "        df_out = df_last_mea[outlier_matrix.sum(axis=1) < outliersbyRow]\n",
        "\n",
        "        # Transforming the matrix as same as df_out to convert remaining outliers into Nan\n",
        "        outlier_matrix = outlier_matrix[outlier_matrix.sum(\n",
        "            axis=1) < outliersbyRow]\n",
        "        df_out = df_out.mask((outlier_matrix))\n",
        "        df_out = pd.concat([df_last.loc[df_last.Part_No == i][first_c],\n",
        "                           df_out], join='inner', axis=1)\n",
        "        # add participant to final df\n",
        "        df_out_final = pd.concat([df_out_final,df_out])\n",
        "    df_out_final.reset_index(inplace=True,drop=True)\n",
        "    return df_out_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afa5e355",
      "metadata": {
        "id": "afa5e355"
      },
      "outputs": [],
      "source": [
        "def OutlierRemoval_OutlierTransformNan(df_last, outliersbyRow=18):\n",
        "    Q1 = df_last[df_last.columns[9:]].quantile(0.25)\n",
        "    Q3 = df_last[df_last.columns[9:]].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    df_last_mea = df_last[df_last.columns[9:]]\n",
        "    df_last_mea = df_last_mea.fillna(df_last_mea.mean())\n",
        "    outlier_matrix = ((df_last_mea < (Q1 - 1.5 * IQR)) |\n",
        "                      (df_last_mea > (Q3 + 1.5 * IQR)))\n",
        "\n",
        "    out_count = (outlier_matrix.sum(axis=1) >= outliersbyRow).sum()\n",
        "    print(f'Row count to be removed:{out_count}, Total Rows: {df_last_mea.shape[0]}'\n",
        "          f'Removing Percentage:{(out_count/df_last_mea.shape[0]*100).round(1)}%')\n",
        "    df_last_mea = df_last[df_last.columns[9:]]\n",
        "\n",
        "    # Removing rows which have > outliersbyRow outlier count\n",
        "    df_out = df_last_mea[outlier_matrix.sum(axis=1) < outliersbyRow]\n",
        "\n",
        "    # Transforming the matrix as same as df_out to convert outliers into Nan\n",
        "    outlier_matrix = outlier_matrix[outlier_matrix.sum(axis=1) < outliersbyRow]\n",
        "    NA_sum_init = df_out.isna().sum().sum()\n",
        "    df_out = df_out.mask((outlier_matrix))\n",
        "    NA_sum_fin = df_out.isna().sum().sum()\n",
        "    print(f\"Total masked values are: {NA_sum_fin-NA_sum_init}\"\n",
        "          f\",{(NA_sum_fin-NA_sum_init)/NA_sum_init*100}.2f% of Initial NA, total NA:{NA_sum_fin}\")\n",
        "    df_out = pd.concat([df_last[df_last.columns[:9]],\n",
        "                       df_out], join='inner', axis=1)\n",
        "    return df_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d9f343",
      "metadata": {
        "id": "e6d9f343"
      },
      "outputs": [],
      "source": [
        "def OutlierTransformNan(df_last):\n",
        "\n",
        "    Q1 = df_last[df_last.columns[9:]].quantile(0.25)\n",
        "    Q3 = df_last[df_last.columns[9:]].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # Outlier dataframe, True means it is an outlier\n",
        "    df_out = (df_last[df_last.columns[9:]] < (Q1 - 1.5 * IQR)\n",
        "              ) | (df_last[df_last.columns[9:]] > (Q3 + 1.5 * IQR))\n",
        "    true_count = (df_out == True).sum(axis=1).sum()\n",
        "    false_count = (df_out == False).sum(axis=1).sum()\n",
        "    print(\"True count: {} False Count: {}\".format(true_count, false_count))\n",
        "\n",
        "    # to check if all values of a row has outlier\n",
        "    print(df_out.shape, df_out[~df_out.all(1)].shape)\n",
        "\n",
        "    # Transforming outliers into NaN\n",
        "    df_last_mea = df_last[df_last.columns[9:]]\n",
        "    df_out = df_last_mea.mask(\n",
        "        ((df_last_mea < (Q1 - 1.5 * IQR)) | (df_last_mea > (Q3 + 1.5 * IQR))))\n",
        "\n",
        "    # Adding non-measurement columns\n",
        "    df_last_out = pd.concat(\n",
        "        [df_last[df_last.columns[:9]], df_out], ignore_index=True, axis=1)\n",
        "    df_last_out.columns = df_last.columns\n",
        "\n",
        "    return df_last_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "797c4870",
      "metadata": {
        "id": "797c4870"
      },
      "outputs": [],
      "source": [
        "def cap_outliers(df, zscore_threshold=4, verbose=False):\n",
        "    '''Caps outliers to closest existing value within threshold (Z-score).'''\n",
        "\n",
        "    c = df.columns[9:]\n",
        "    participant = df['Part_No'].unique()\n",
        "    for i in participant:\n",
        "        # mean_val = series.loc[series.Part_No == i][c].mean()\n",
        "        # std_val = series.loc[series.Part_No == i][c].std()\n",
        "\n",
        "        # lbound = mean_val - zscore_threshold * std_val\n",
        "        # ubound = mean_val + zscore_threshold * std_val\n",
        "\n",
        "        lbound = df.loc[df.Part_No == i][c].quantile(0.25)\n",
        "        ubound = df.loc[df.Part_No == i][c].quantile(0.75)\n",
        "        threshold = ubound - lbound\n",
        "\n",
        "        df = df.copy()\n",
        "        df.loc[df.Part_No == i, c] = df.loc[df.Part_No == i][c].clip(\n",
        "            lbound - 1.5*threshold, ubound + 1.5*threshold, axis=1)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af700617",
      "metadata": {
        "id": "af700617"
      },
      "source": [
        "# Standardization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24103b84",
      "metadata": {
        "id": "24103b84"
      },
      "outputs": [],
      "source": [
        "def standardization_byParticipant(df):\n",
        "    c = df.columns[:-1]\n",
        "    participant = df['Part_No'].unique()\n",
        "    df_final=pd.DataFrame(columns=c)\n",
        "    for i in participant:\n",
        "      scaler = StandardScaler()\n",
        "      std = df.loc[df.Part_No == i][c]\n",
        "      std = scaler.fit_transform(std)\n",
        "      df_std = pd.DataFrame(std,columns=c)\n",
        "      # print(df_std)\n",
        "      # break\n",
        "      df_final = pd.concat([df_final,df_std])\n",
        "    df_final.reset_index(inplace=True,drop=True)\n",
        "    return df_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "036c6611",
      "metadata": {
        "id": "036c6611"
      },
      "outputs": [],
      "source": [
        "def standardization_byRows(df):\n",
        "  c = df.columns[:-1] \n",
        "  std = df[c].sub(df[c].mean(1), axis=0).div(df[c].std(1), axis=0)\n",
        "  # df_std = pd.DataFrame(std,columns=c)\n",
        "  return std"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YybRAgDDwBvN",
      "metadata": {
        "id": "YybRAgDDwBvN"
      },
      "source": [
        "# FAA Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dd54f86",
      "metadata": {
        "id": "1dd54f86"
      },
      "outputs": [],
      "source": [
        "def avg_lr(df):\n",
        "    df_avg_lr = df.copy()\n",
        "    df_avg_lr.drop(df_avg_lr.iloc[:,9:], inplace=True, axis=1)\n",
        "\n",
        "    df_avg_lr['Goxy_Avg'] = df.iloc[:,9:17].mean(axis=1) / df.iloc[:,17:25].mean(axis=1)\n",
        "    df_avg_lr['Ghbr_Avg'] = df.iloc[:,25:33].mean(axis=1) / df.iloc[:,33:41].mean(axis=1)\n",
        "    df_avg_lr['Ghbo_Avg'] = df.iloc[:,41:49].mean(axis=1) / df.iloc[:,49:57].mean(axis=1)\n",
        "    df_avg_lr['Ghbt_Avg'] = df.iloc[:,57:65].mean(axis=1) / df.iloc[:,65:73].mean(axis=1)\n",
        "\n",
        "    df_avg_lr['Koxy_Avg'] = df.iloc[:,73:81].mean(axis=1) / df.iloc[:,81:89].mean(axis=1)\n",
        "    df_avg_lr['Khbr_Avg'] = df.iloc[:,89:97].mean(axis=1) / df.iloc[:,97:105].mean(axis=1)\n",
        "    df_avg_lr['Khbo_Avg'] = df.iloc[:,105:113].mean(axis=1) / df.iloc[:,113:121].mean(axis=1)\n",
        "    df_avg_lr['Khbt_Avg'] = df.iloc[:,121:129].mean(axis=1) / df.iloc[:,129:137].mean(axis=1)\n",
        "\n",
        "    # df_avg_lr['Goxy_Avg9-16'] = df_cleaned.iloc[:,25:33].mean(axis=1)\n",
        "    return df_avg_lr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Az2TRR6QwGop",
      "metadata": {
        "id": "Az2TRR6QwGop"
      },
      "source": [
        "# FAA Transformation with Creating a FAA Feature - 1 for left region and 0 for right region dominance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ah8pI4Spwkk7",
      "metadata": {
        "id": "ah8pI4Spwkk7"
      },
      "outputs": [],
      "source": [
        "def FAA_dominance(df):\n",
        "    df_avg_lr = df.copy()\n",
        "    \n",
        "    df_avg_lr['Goxy_FAA_Index'] = df.iloc[:,9:17].mean(axis=1) - df.iloc[:,17:25].mean(axis=1)\n",
        "    df_avg_lr['Koxy_FAA_Index'] = df.iloc[:,73:81].mean(axis=1) - df.iloc[:,81:89].mean(axis=1)\n",
        "\n",
        "    # df_avg_lr['Goxy_Avg9-16'] = df_cleaned.iloc[:,25:33].mean(axis=1)\n",
        "    return df_avg_lr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55f0c4a6",
      "metadata": {
        "id": "55f0c4a6"
      },
      "source": [
        "# Kmeans & GMM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3484f6f9",
      "metadata": {
        "id": "3484f6f9"
      },
      "outputs": [],
      "source": [
        "def amountByCluster(df,clusterNum):\n",
        "    df_prc = pd.DataFrame(df_avgiter_GMM_onehot_cl2.iloc[:,-clusterNum:].sum())\n",
        "    df_prc[1] = 0\n",
        "    for i in range(0,clusterNum):\n",
        "        df_prc.iloc[i,1] = df_prc.iloc[i,0] / df_prc.iloc[:,0].sum() * 100\n",
        "\n",
        "    return df_prc.sort_values(by=0, ascending=False)\n",
        "\n",
        "\n",
        "def gmm_js(gmm_p, gmm_q, n_samples=10**5):\n",
        "    X = gmm_p.sample(n_samples)[0]\n",
        "    log_p_X = gmm_p.score_samples(X)\n",
        "    log_q_X = gmm_q.score_samples(X)\n",
        "    log_mix_X = np.logaddexp(log_p_X, log_q_X)\n",
        "\n",
        "    Y = gmm_q.sample(n_samples)[0]\n",
        "    log_p_Y = gmm_p.score_samples(Y)\n",
        "    log_q_Y = gmm_q.score_samples(Y)\n",
        "    log_mix_Y = np.logaddexp(log_p_Y, log_q_Y)\n",
        "\n",
        "    return np.sqrt((log_p_X.mean() - (log_mix_X.mean() - np.log(2))\n",
        "            + log_q_Y.mean() - (log_mix_Y.mean() - np.log(2))) / 2)\n",
        "\n",
        "def df_Kmeans_evaluation(df):\n",
        "    \n",
        "    df_age_sex = pd.read_csv(r'FNIRS_bilgi.csv')\n",
        "#     df_age_sex = pd.read_csv(r'/content/drive/MyDrive/Master/Tez/FNIRS_bilgi.csv')\n",
        "    df_age_sex.columns = ['Part_No', 'Gender', 'Age', 'Education']\n",
        "    \n",
        "    # Merging gender data with main data\n",
        "    df_whole = pd.merge(df_age_sex, \n",
        "                          df, \n",
        "                          on ='Part_No', \n",
        "                          how ='inner')\n",
        "    \n",
        "    # Gender One Hot Encoding\n",
        "    One_enc = OneHotEncoder(handle_unknown='ignore')\n",
        "    enc_df = pd.DataFrame(One_enc.fit_transform(df_whole[['Gender']]).toarray())\n",
        "    df_whole = df_whole.join(enc_df)\n",
        "    df_whole.rename(columns = {0:'Male', 1:'Female'}, inplace = True)\n",
        "    \n",
        "    Z = df_whole.groupby(['Part_No'], as_index = False).mean()\n",
        "    \n",
        "#     s_scores = []\n",
        "#     for i in range(2,10):\n",
        "#         KMean = KMeans(n_clusters=i)\n",
        "#         KMean.fit(Z.iloc[:,8:16])\n",
        "#         label = KMean.predict(Z.iloc[:,8:16])\n",
        "#         print(f'Silhouette Score(n={i}): {silhouette_score(Z.iloc[:,8:16], label)}')\n",
        "#         s_scores.append(silhouette_score(Z.iloc[:,8:16], label))\n",
        "#     plt.plot(np.arange(2,20), s_scores)\n",
        "#     plt.title('Silhouette Score of K-Means')\n",
        "#     plt.xlabel('Cluster Number')\n",
        "#     plt.ylabel('Sİlhouette Score')\n",
        "#     plt.show()\n",
        "\n",
        "    # Silhouette Score\n",
        "    n_components = np.arange(2, 20)\n",
        "    models = [KMeans(n_clusters = n).fit(Z.iloc[:,9:]) for n in n_components]\n",
        "    labels = [model.predict(Z.iloc[:,9:]) for model in models]\n",
        "    plt.plot(n_components, [silhouette_score(Z.iloc[:,9:], label) for label in labels] )\n",
        "    plt.title('Silhouette Score of K-Means')\n",
        "    plt.xlabel('Cluster Number')\n",
        "    plt.ylabel('Silhouette Score')\n",
        "    plt.xticks(np.arange(1,20,1))\n",
        "    plt.show()\n",
        "    \n",
        "def df_Kmeans_silhouette(df, clusters):\n",
        "    \n",
        "    df_age_sex = pd.read_csv(r'FNIRS_bilgi.csv')\n",
        "#     df_age_sex = pd.read_csv(r'/content/drive/MyDrive/Master/Tez/FNIRS_bilgi.csv')\n",
        "    df_age_sex.columns = ['Part_No', 'Gender', 'Age', 'Education']\n",
        "    \n",
        "    # Merging gender data with main data\n",
        "    df_whole = pd.merge(df_age_sex, \n",
        "                          df, \n",
        "                          on ='Part_No', \n",
        "                          how ='inner')\n",
        "    \n",
        "    # Gender One Hot Encoding\n",
        "    One_enc = OneHotEncoder(handle_unknown='ignore')\n",
        "    enc_df = pd.DataFrame(One_enc.fit_transform(df_whole[['Gender']]).toarray())\n",
        "    df_whole = df_whole.join(enc_df)\n",
        "    df_whole.rename(columns = {0:'Male', 1:'Female'}, inplace = True)\n",
        "    Z = df_whole.groupby(['Part_No'], as_index = False).mean()\n",
        "\n",
        "    # K-means Clustering and its One Hot Encoding\n",
        "    KMean = KMeans(n_clusters=clusters)\n",
        "    KMean.fit(Z.iloc[:,9:])\n",
        "    label = KMean.predict(Z.iloc[:,9:])\n",
        "    Z['Clusters'] = label\n",
        "    Z = Z[['Part_No']].join(Z['Clusters'])    \n",
        "    df_whole = pd.merge(df_whole, \n",
        "                          Z, \n",
        "                          on ='Part_No', \n",
        "                          how ='inner')    \n",
        "    One_enc_2 = OneHotEncoder(handle_unknown='ignore')\n",
        "    enc_df_2 = pd.DataFrame(One_enc_2.fit_transform(df_whole[['Clusters']]).toarray())\n",
        "    df_whole = df_whole.join(enc_df_2)    \n",
        "#     df_whole.rename(columns = {0:'Cluster 1', 1:'Cluster 2'}, inplace = True)    \n",
        "    df_whole.drop(['Clusters', 'Gender', 'Age', 'Education'], inplace = True, axis = 1)\n",
        "    \n",
        "    return df_whole    \n",
        "\n",
        "\n",
        "def df_GMM_evaluation(df):\n",
        "    \n",
        "    df_age_sex = pd.read_csv(r'FNIRS_bilgi.csv')\n",
        "#     df_age_sex = pd.read_csv(r'/content/drive/MyDrive/Master/Tez/FNIRS_bilgi.csv')\n",
        "    df_age_sex.columns = ['Part_No', 'Gender', 'Age', 'Education']\n",
        "    \n",
        "    # Merging gender data with main data\n",
        "    df_whole = pd.merge(df_age_sex, \n",
        "                          df, \n",
        "                          on ='Part_No', \n",
        "                          how ='inner')\n",
        "    \n",
        "    # Gender One Hot Encoding\n",
        "    One_enc = OneHotEncoder(handle_unknown='ignore')\n",
        "    enc_df = pd.DataFrame(One_enc.fit_transform(df_whole[['Gender']]).toarray())\n",
        "    df_whole = df_whole.join(enc_df)\n",
        "    df_whole.rename(columns = {0:'Male', 1:'Female'}, inplace = True)\n",
        "    Z = df_whole.groupby(['Part_No'], as_index = False).mean()\n",
        "    \n",
        "\n",
        "    # Silhouette Score\n",
        "#     n_components = np.arange(2, 20)\n",
        "#     models = [GMM(n_components = n, covariance_type='full').fit(Z.iloc[:,9:]) for n in n_components]\n",
        "#     labels = [model.predict(Z.iloc[:,9:]) for model in models]\n",
        "#     plt.plot(n_components, [silhouette_score(Z.iloc[:,9:], label) for label in labels] )\n",
        "#     plt.title('Silhouette Score of GMM')\n",
        "#     plt.xlabel('Cluster Number')\n",
        "#     plt.ylabel('Silhouette Score')\n",
        "#     plt.xticks(np.arange(1,20,1))\n",
        "#     plt.show()\n",
        "    \n",
        "    # BIC/AIC Score\n",
        "    n_components_ = np.arange(2, 20)\n",
        "    models = [GMM(n, covariance_type='full', random_state=0).fit(Z.iloc[:,9:])\n",
        "          for n in n_components_]\n",
        "\n",
        "    plt.plot(n_components_, [m.bic(Z.iloc[:,9:]) for m in models], label='BIC')\n",
        "    plt.plot(n_components_, [m.aic(Z.iloc[:,9:]) for m in models], label='AIC')\n",
        "    plt.legend(loc='best')\n",
        "    plt.title('BIC AIC Evaluation')\n",
        "    plt.xlabel('n_components')\n",
        "    plt.ylabel('Score')\n",
        "    plt.xticks(np.arange(1,20,1))\n",
        "    plt.show()\n",
        "    \n",
        "    #Jensen Shannon Divergence Score/Distances\n",
        "#     js_scores = []\n",
        "#     for n in n_components_:\n",
        "#         train, test = train_test_split(Z.iloc[:,9:], test_size=0.5)\n",
        "#         norm = MinMaxScaler()\n",
        "#         train_norm = norm.fit_transform(train).reshape(-1,1)\n",
        "#         test_norm = norm.transform(test).reshape(-1,1)\n",
        "#         gmm_train = GMM(n_components = n, covariance_type='full' ).fit(train_norm) \n",
        "#         gmm_test = GMM(n_components = n, covariance_type='full').fit(test_norm) \n",
        "#         js_scores.append(gmm_js(gmm_train, gmm_test))    \n",
        "    \n",
        "#     plt.plot(n_components, js_scores)\n",
        "#     plt.title('Jensen Shannon Divergence GMM')\n",
        "#     plt.xlabel('Cluster Number')\n",
        "#     plt.ylabel('Distance')\n",
        "#     plt.xticks(np.arange(1,20,1))\n",
        "#     plt.show()\n",
        "    \n",
        "\n",
        "def df_GMM(df, clusters):\n",
        "    \n",
        "    df_age_sex = pd.read_csv(r'FNIRS_bilgi.csv')\n",
        "#     df_age_sex = pd.read_csv(r'/content/drive/MyDrive/Master/Tez/FNIRS_bilgi.csv')\n",
        "    df_age_sex.columns = ['Part_No', 'Gender', 'Age', 'Education']\n",
        "    \n",
        "    # Merging gender data with main data\n",
        "    df_whole = pd.merge(df_age_sex, \n",
        "                          df,  \n",
        "                          on ='Part_No', \n",
        "                          how ='inner')\n",
        "    \n",
        "    # Gender One Hot Encoding\n",
        "    One_enc = OneHotEncoder(handle_unknown='ignore')\n",
        "    enc_df = pd.DataFrame(One_enc.fit_transform(df_whole[['Gender']]).toarray())\n",
        "    df_whole = df_whole.join(enc_df)\n",
        "    df_whole.rename(columns = {0:'Male', 1:'Female'}, inplace = True)\n",
        "    Z = df_whole.groupby(['Part_No'], as_index = False).mean()\n",
        "    \n",
        "    # GMM Clustering and its One Hot Encoding\n",
        "    GMM_ = GMM(n_components = clusters, covariance_type='full' ).fit(Z.iloc[:,9:]) \n",
        "    label = GMM_.predict(Z.iloc[:,9:])\n",
        "    Z['Clusters'] = label    \n",
        "    Z = Z[['Part_No']].join(Z['Clusters'])\n",
        "    df_whole = pd.merge(df_whole, \n",
        "                          Z, \n",
        "                          on ='Part_No', \n",
        "                          how ='inner')    \n",
        "    One_enc_2 = OneHotEncoder(handle_unknown='ignore')\n",
        "    enc_df_2 = pd.DataFrame(One_enc_2.fit_transform(df_whole[['Clusters']]).toarray())\n",
        "    df_whole = df_whole.join(enc_df_2)\n",
        "#     df_whole.rename(columns = {0:'Cluster 1', 1:'Cluster 2'}, inplace = True)\n",
        "    \n",
        "    # Dropping unnecassary columns as to make it same shape as other data\n",
        "    df_whole.drop(['Clusters', 'Gender', 'Age', 'Education'], inplace = True, axis = 1)\n",
        "\n",
        "    return df_whole"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35d32df1",
      "metadata": {
        "id": "35d32df1"
      },
      "source": [
        "# Permutation Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wO3nocc3N-v4",
      "metadata": {
        "id": "wO3nocc3N-v4"
      },
      "outputs": [],
      "source": [
        "def permutation_test(fitted_model, X_test, Y_test, n_permutations):\n",
        "  fitted_model.predict(X_test)\n",
        "  score = fitted_model.score(X_test,Y_test)\n",
        "  permutation_scores = []\n",
        "  higher_count = 0\n",
        "  for i in range(n_permutations):\n",
        "    Y_test_perm = shuffle(Y_test,random_state=i) \n",
        "    perm_score = fitted_model.score(X_test,Y_test_perm)\n",
        "    permutation_scores.append(perm_score)\n",
        "    if perm_score >= score:\n",
        "      higher_count += 1\n",
        "  p_value = (1 + higher_count) / (1+ n_permutations)\n",
        "\n",
        "  return score, permutation_scores, p_value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37421aab",
      "metadata": {
        "id": "37421aab"
      },
      "outputs": [],
      "source": [
        "def permutationTest(model, X_train, Y_train, cv, groups, n=50):\n",
        "    score, perm_scores, pvalue = permutation_test_score(\n",
        "    model, X_train, Y_train, groups=groups, scoring=\"accuracy\", cv=cv, n_permutations=n)\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    ax.hist(perm_scores, bins=20, density=True)\n",
        "    ax.axvline(score, ls=\"--\", color=\"r\")\n",
        "    score_label = f\"Score on original\\ndata: {score:.2f}\\n(p-value: {pvalue:.4f})\"\n",
        "    ax.text(0.7, 10, score_label, fontsize=12)\n",
        "    ax.set_xlabel(\"F1 score\")\n",
        "    ax.set_ylabel(\"Probability\")\n",
        "    plt.show()\n",
        "    return \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbb87349",
      "metadata": {
        "id": "fbb87349"
      },
      "outputs": [],
      "source": [
        "def permutation_importance(model_, X_pca_train, Y_train):   \n",
        "    # perform permutation importance\n",
        "    results = permutation_importance(model_, X_pca_train, Y_train, scoring='accuracy')\n",
        "    # get importance\n",
        "    importance = results.importances_mean\n",
        "    # summarize feature importance\n",
        "    for i,v in enumerate(importance):\n",
        "        print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "    # plot feature importance\n",
        "    plt.bar([x for x in range(len(importance))], importance)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VGQ5TM_ignwy",
      "metadata": {
        "id": "VGQ5TM_ignwy"
      },
      "source": [
        "# EXPLANIED VARIANCE RATIO AND FEATURE NUMBER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W7_yR8xbgF8b",
      "metadata": {
        "id": "W7_yR8xbgF8b"
      },
      "outputs": [],
      "source": [
        "def n_to_reach(df,featureCount, variance):\n",
        "    \n",
        "    print('Finding feature number to be reduced to given the explained variance ratio...')\n",
        "    df = pd.concat([df[df.columns[8:]], df[df.columns[6]]], ignore_index=True, axis=1)\n",
        "    i = df.shape[1] - (featureCount + 1)\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    df.iloc[:,1:-i], df.iloc[:,0], test_size=0.2, random_state=0)\n",
        "        \n",
        "    # finding n_components for maintaining specified variance\n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    print(\"Starting PCA...\")\n",
        "    start = time.time()\n",
        "    pca = PCA()    \n",
        "    X_pca_train = pca.fit_transform(X_train_scaled)\n",
        "    \n",
        "    total_explained_variance = pca.explained_variance_ratio_.cumsum()\n",
        "    n_over = len(total_explained_variance[total_explained_variance >= variance])\n",
        "    n_to_reach = X_train.shape[1] - n_over + 1\n",
        "    print(\"Number features: {}\\tTotal Variance Explained: {}\"\n",
        "          .format(n_to_reach, total_explained_variance[n_to_reach-1]))\n",
        "    return n_to_reach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O56caY0XYjws",
      "metadata": {
        "id": "O56caY0XYjws"
      },
      "outputs": [],
      "source": [
        "global lgb_param\n",
        "global rfc_param\n",
        "global svm_param\n",
        "global knn_param\n",
        "global xgb_param\n",
        "global pos_weight\n",
        "pos_weight = 0.88\n",
        "\n",
        "lgb_param = {\n",
        "                    'boosting_type': ['gbtree','dart'],\n",
        "                    'num_leaves': [16,48,96],\n",
        "                    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
        "                    'max_depth': [3,4,5],\n",
        "                    'max_bin': [10,50,100],\n",
        "#                     'n_estimators' : [500,1000]\n",
        "#                 'boosting_type': ['gbdt', 'goss', 'dart'],\n",
        "#                 'num_leaves': list(range(10, 20)),\n",
        "#                 'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
        "#                 'max_depth':list(range(1,12)),\n",
        "#                 'max_bin': list(range(2, 30)),\n",
        "                'num_iterations': [100,300,500],\n",
        "                'early_stopping_rounds': [5,10],\n",
        "                'scale_pos_weight': [pos_weight],\n",
        "                'n_jobs' : [-1],\n",
        "                'path_smooth': [3,4,5],\n",
        "                'random_state': [0]\n",
        "                     }\n",
        "rfc_param =  {'bootstrap': [True],\n",
        "                       'max_depth': [3, 4, 5],\n",
        "                       'n_estimators': [300,500,1000],\n",
        "                       'criterion' :['gini', 'entropy']\n",
        "                     }\n",
        "svm_param = {'C': [0.01, 0.1, 1, 3, 5],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['linear']\n",
        "                     }\n",
        "\n",
        "knn_param = {'n_neighbors': list(range(3,21)),\n",
        "              'metric': ['euclidean']\n",
        "                   }\n",
        "\n",
        "xgb_param = {'learning_rate':[0.01, 0.03, 0.05, 0.1],\n",
        "                'max_depth':[3,4,5],\n",
        "                'booster': ['gbtree','dart'],\n",
        "                'random_state': [0],\n",
        "                'n_jobs': [-1],\n",
        "                'scale_pos_weight': [pos_weight],\n",
        "                'gamma': [1, 5, 10],\n",
        "                'n_estimators': [100,300,500],\n",
        "                'min_child_weight': list(range(3,8)),\n",
        "                'use_label_encoder': [False],\n",
        "                'early_stopping_rounds':  [5,10],\n",
        "                'objective': ['binary:logistic'], \n",
        "                'eval_metric': ['auc'],\n",
        "                'verbosity': [0]\n",
        "                     }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17b3d29b",
      "metadata": {
        "id": "17b3d29b"
      },
      "source": [
        "# ALL MODELS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0e4e354",
      "metadata": {
        "id": "c0e4e354"
      },
      "outputs": [],
      "source": [
        "def main_model_wrapperMethod(df, model, model_name, featureCount, SMOTEBool=False, distance='euclidean', cv_splits=5, random_state=0, method='original', n_to_reach=0.99, groupBool=False,verbose=False, wrapper=True, cv_resultsBool=False):\n",
        "    \n",
        "    # df = pd.concat([df[df.columns[8:]], df[df.columns[0]]], ignore_index=True, axis=1)\n",
        "    cols = df.columns.tolist()\n",
        "    df = df[cols[8:]+[cols[0]]]\n",
        "    i = df.shape[1] - (featureCount + 1)\n",
        "\n",
        "    # Parameter tuning\n",
        "    param_grid = {}\n",
        "    if model_name == 'lgb':\n",
        "      param_grid=lgb_param\n",
        "    elif model_name == 'rfc':\n",
        "      param_grid=rfc_param \n",
        "    elif model_name == 'SVM':\n",
        "       param_grid=svm_param\n",
        "    elif model_name == 'KNN':\n",
        "      param_grid=knn_param\n",
        "    elif model_name == 'XGB':\n",
        "      param_grid=xgb_param\n",
        "\n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    \n",
        "    # Normalization\n",
        "#     scaler = MinMaxScaler()\n",
        "    if groupBool:\n",
        "      groups = df.Part_No.tolist()\n",
        "    else:\n",
        "      groups=None\n",
        "    # df = df.iloc[:,:-1]\n",
        "    X = df.iloc[:,1:]\n",
        "    y = df.iloc[:,0]\n",
        "\n",
        "    # Pipeline\n",
        "    if method == 'original':\n",
        "      # TODO: std by subject\n",
        "      if wrapper:\n",
        "        start = time.time()\n",
        "        sfs = SFS(model,\n",
        "            n_features_to_select=int(df.shape[1]/6),\n",
        "            direction='forward',\n",
        "            cv = cv_splits,\n",
        "            n_jobs=-1)\n",
        "        X = scaler.fit_transform(X)\n",
        "        X = sfs.fit_transform(X, y)\n",
        "        if verbose:\n",
        "          print(f\"Wrapper= {str(datetime.timedelta(seconds=(time.time()-start)))}\")\n",
        "      else:\n",
        "        name = 'clf__'\n",
        "        param_grid = {f\"{name}{key}\" : value for key, value in  param_grid.items()}\n",
        "        pipe = Pipeline(steps=[('scaler', scaler),\n",
        "                      ('clf', model)])\n",
        "    elif method == 'PCA':\n",
        "      start=time.time()\n",
        "      pca = PCA(n_components=n_to_reach)\n",
        "      # X = standardization_byParticipant(X)\n",
        "      X = standardization_byRows(X)\n",
        "      start = time.time()\n",
        "      X = pca.fit_transform(X)\n",
        "      if verbose:\n",
        "        print(f\"PCA= {str(datetime.timedelta(seconds=(time.time()-start)))}\")\n",
        "      if wrapper:\n",
        "        start = time.time()\n",
        "        sfs = SFS(model,\n",
        "            n_features_to_select=int(2*len(pca.components_)/3),\n",
        "            direction='forward',\n",
        "            cv = cv_splits,\n",
        "            n_jobs=-1)\n",
        "        X = sfs.fit_transform(X, y)\n",
        "        if verbose:\n",
        "          print(f\"Wrapper= {str(datetime.timedelta(seconds=(time.time()-start)))}\")\n",
        "    elif method == 'ISOMAP':\n",
        "      X = scaler.fit_transform(X)\n",
        "      n_to_reach = explained_variance(X, n_to_reach)\n",
        "      iso = Isomap(n_components=n_to_reach)\n",
        "      X = iso.fit_transform(X)\n",
        "      if wrapper:\n",
        "        start = time.time()\n",
        "        sfs = SFS(model,\n",
        "            n_features_to_select=int(2*len(n_to_reach)/3),\n",
        "            direction='forward',\n",
        "            cv = cv_splits,\n",
        "            n_jobs=-1)\n",
        "        X = sfs.fit_transform(X, y)\n",
        "        if verbose:\n",
        "          print(f\"Wrapper= {str(datetime.timedelta(seconds=(time.time()-start)))}\")\n",
        "    elif method == 'TSNE':\n",
        "      X = scaler.fit_transform(X)\n",
        "      n_to_reach = explained_variance(X,n_to_reach)\n",
        "      tsne = TSNE(n_components=n_to_reach, init='pca', random_state=0, method='exact', n_jobs=-1, learning_rate = 0.1, n_iter=500)\n",
        "      X = tsne.fit_transform(X)\n",
        "      if wrapper:\n",
        "        start = time.time()\n",
        "        sfs = SFS(model,\n",
        "            n_features_to_select=int(2*len(n_to_reach)/3),\n",
        "            direction='forward',\n",
        "            cv = cv_splits,\n",
        "            n_jobs=-1)\n",
        "        X = sfs.fit_transform(X, y)\n",
        "        if verbose:\n",
        "          print(f\"Wrapper= {str(datetime.timedelta(seconds=(time.time()-start)))}\")\n",
        "    \n",
        "    #SMOTE for Train Data to Balance Dataset and also to Increase Data Size\n",
        "    if SMOTEBool == True:\n",
        "        print('SMOTE is being applied to the train set...')\n",
        "        oversample = SMOTE()\n",
        "        X, y = oversample.fit_resample(X, y)\n",
        "    \n",
        "    # K-fold cross validation\n",
        "    start = time.time()\n",
        "    if groupBool:\n",
        "      cv = StratifiedGroupKFold(n_splits=cv_splits, random_state=1, shuffle=True)\n",
        "      \n",
        "    else:\n",
        "      cv = StratifiedKFold(n_splits=cv_splits, random_state=1, shuffle=True)\n",
        "    if cv_resultsBool:\n",
        "      if method == 'TSNE' or method =='ISOMAP' or \\\n",
        "          method == 'PCA' or (method=='original' and wrapper==True):\n",
        "        cv_results = cross_val_score(model, X, y, groups=groups, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "      else:\n",
        "        cv_results = cross_val_score(pipe, X, y, groups=groups, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "      # print('Cross Validation Accuracy: %.3f (%.3f)' % (np.mean(cv_results), np.std(cv_results)))\n",
        "    else:\n",
        "      cv_results = None\n",
        "\n",
        "    if verbose:\n",
        "      print(f\"StratifiedGroupKFold = {str(datetime.timedelta(seconds=(time.time()-start)))}\")\n",
        "\n",
        "    # Trial for Mahalanobis distance metric for KNN -- seems worse than euclidean so commented\n",
        "    # if model_name == 'KNN' and distance == 'mahalanobis':\n",
        "        \n",
        "    #     param_grid = {'n_neighbors': list(range(3,21)),\n",
        "    #           'metric': ['mahalanobis'],\n",
        "    #           'algorithm': ['brute'],\n",
        "    #           'metric_params': [{'VI': np.linalg.inv(np.cov(X))}]\n",
        "    #     }\n",
        "    # GridSearch for Hyperparameters\n",
        "    start = time.time()\n",
        "    if method=='original' and wrapper==False:\n",
        "      model_ = GridSearchCV(pipe,           \n",
        "                            param_grid = param_grid,    \n",
        "                            scoring='accuracy',         \n",
        "                            cv=cv,                      \n",
        "                            n_jobs=-1)\n",
        "      \n",
        "    else:\n",
        "      model_ = GridSearchCV(model,           \n",
        "                            param_grid = param_grid,    \n",
        "                            scoring='accuracy',         \n",
        "                            cv=cv,                      \n",
        "                            n_jobs=-1)  \n",
        "               \n",
        "    model_.fit(X, y, groups=groups)\n",
        "\n",
        "    if verbose:\n",
        "      print(f\"GridSearch = {str(datetime.timedelta(seconds=(time.time()-start)))}\")\n",
        "    \n",
        "    if method =='PCA':\n",
        "      try:\n",
        "        sfs\n",
        "        return [cv_results, sfs, pca, model_]\n",
        "      except:\n",
        "        return [cv_results, None, pca, model_]\n",
        "    else:\n",
        "      try:\n",
        "        sfs\n",
        "        return [cv_results, sfs, None, model_]\n",
        "      except:\n",
        "        return [cv_results, None, None, model_]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df6538e",
      "metadata": {
        "id": "2df6538e"
      },
      "source": [
        "# MAIN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6iJesGX6pYaV",
      "metadata": {
        "id": "6iJesGX6pYaV"
      },
      "outputs": [],
      "source": [
        "def main_model_new(df, model, model_name, featureCount, SMOTEBool=False, distance='euclidean', cv_splits=5, random_state=0, method='original', n_to_reach=0.95):\n",
        "    \n",
        "    df = pd.concat([df[df.columns[8:]], df[df.columns[6]]], ignore_index=True, axis=1)\n",
        "    i = df.shape[1] - (featureCount + 1)\n",
        "\n",
        "    # Group Split of Data into Train/Test\n",
        "    # X = df.iloc[:,1:-i]\n",
        "    # X.reset_index(inplace=True,drop=True)\n",
        "    # Y = df.iloc[:,0]\n",
        "    # Y.reset_index(inplace=True,drop=True)\n",
        "    # groups = df.iloc[:,-1:] \n",
        "    # groups.reset_index(inplace=True,drop=True)\n",
        "\n",
        "    # gss = GroupShuffleSplit(n_splits=1, train_size=.8, random_state=0)\n",
        "    # gss.get_n_splits()\n",
        "    # for train_index, test_index in gss.split(X,Y, groups):\n",
        "    #   X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "      # Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
        "\n",
        "    # X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    # df.iloc[:,1:-i], df.iloc[:,0], test_size=0.20, random_state=random_state)\n",
        "    print('MAIN RESULTS')\n",
        "    # pos_weight = sum(Y_train[Y_train == 0]) / sum(Y_train[Y_train == 1])\n",
        "    # train_weight = sum(1 if x == 0 else 0 for x in Y_train)\\\n",
        "    #                     /sum(1 if x == 1 else 0 for x in Y_train)\n",
        "\n",
        "    # Parameter tuning\n",
        "    param_grid = {}\n",
        "    if model_name == 'lgb':\n",
        "      param_grid=lgb_param\n",
        "    elif model_name == 'rfc':\n",
        "      param_grid=rfc_param \n",
        "    elif model_name == 'SVM':\n",
        "       param_grid=svm_param\n",
        "    elif model_name == 'KNN':\n",
        "      param_grid=knn_param\n",
        "    elif model_name == 'XGB':\n",
        "      param_grid=xgb_param\n",
        "\n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    \n",
        "    # Normalization\n",
        "#     scaler = MinMaxScaler()\n",
        "    \n",
        "    \n",
        "    # Pipeline\n",
        "    if method == 'original':\n",
        "      pipe = Pipeline([('scaler', scaler),\n",
        "                      ('clf', model)])\n",
        "    elif method == 'PCA':\n",
        "      pipe = Pipeline([('scaler', scaler),\n",
        "                       ('pca'), PCA(n_components=n_to_reach)\n",
        "                      ('clf', model)])\n",
        "    elif method == 'ISOMAP':\n",
        "      pipe = Pipeline([('scaler', scaler),\n",
        "                       ('iso'), Isomap(n_components=n_to_reach)\n",
        "                      ('clf', model)])\n",
        "    elif method == 'T-SNE':\n",
        "      pipe = Pipeline([('scaler', scaler),\n",
        "                       ('tsne'), TSNE(n_components=n_to_reach)\n",
        "                      ('clf', model)])\n",
        "\n",
        "   \n",
        "    groups = df.iloc[:,-1]\n",
        "    df = df.iloc[:,:-1]\n",
        "    X = df.iloc[:,0]\n",
        "    y = df.iloc[:,1:]\n",
        "\n",
        "    #SMOTE for Train Data to Balance Dataset and also to Increase Data Size\n",
        "    if SMOTEBool == True:\n",
        "        print('SMOTE is being applied to the train set...')\n",
        "        oversample = SMOTE()\n",
        "        X, y = oversample.fit_resample(X, y)\n",
        "    \n",
        "    # K-fold cross validation\n",
        "    print('Starting StratifiedGroupKFold...')\n",
        "    start = time.time()\n",
        "    cv = StratifiedGroupKFold(n_splits=cv_splits, random_state=1, shuffle=True)\n",
        "    cv_results = cross_val_score(pipe, X, y, groups=groups, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "    print('Cross Validation Accuracy: %.3f (%.3f)' % (np.mean(cv_results), np.std(cv_results)))\n",
        "    end = time.time()\n",
        "    print(f\"Total Time of StratifiedGroupKFold = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "\n",
        "    # Trial for Mahalanobis distance metric for KNN -- seems worse than euclidean so commented\n",
        "    if model_name == 'KNN' and distance == 'mahalanobis':\n",
        "        \n",
        "        param_grid = {'n_neighbors': list(range(3,21)),\n",
        "              'metric': ['mahalanobis'],\n",
        "              'algorithm': ['brute'],\n",
        "              'metric_params': [{'VI': np.linalg.inv(np.cov(X))}]\n",
        "        }\n",
        "    # GridSearch for Hyperparameters\n",
        "    print(\"Starting fitting into the model...\")\n",
        "    # start = time.time()\n",
        "    # model_ = GridSearchCV(model,           \n",
        "    #           param_grid = param_grid,    \n",
        "    #           scoring='accuracy',         \n",
        "    #           cv=cv,                      \n",
        "    #           n_jobs=-1)             \n",
        "    # model_.fit(X_train, Y_train, groups=groups)\n",
        "    # end = time.time()\n",
        "    # print(f\"Total Time of model fit = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "\n",
        "\n",
        "    return [X, y, groups, cv_results]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fe6744e",
      "metadata": {
        "id": "6fe6744e"
      },
      "outputs": [],
      "source": [
        "def main_model(df, model, model_name, featureCount, SMOTEBool=False, distance='euclidean', cv_splits=5, random_state=0):\n",
        "    \n",
        "    df = pd.concat([df[df.columns[8:]], df[df.columns[6]]], ignore_index=True, axis=1)\n",
        "    i = df.shape[1] - (featureCount + 1)\n",
        "\n",
        "    # Group Split of Data into Train/Test\n",
        "    # X = df.iloc[:,1:-i]\n",
        "    # X.reset_index(inplace=True,drop=True)\n",
        "    # Y = df.iloc[:,0]\n",
        "    # Y.reset_index(inplace=True,drop=True)\n",
        "    # groups = df.iloc[:,-1:] \n",
        "    # groups.reset_index(inplace=True,drop=True)\n",
        "\n",
        "    # gss = GroupShuffleSplit(n_splits=1, train_size=.8, random_state=0)\n",
        "    # gss.get_n_splits()\n",
        "    # for train_index, test_index in gss.split(X,Y, groups):\n",
        "    #   X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "      # Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
        "\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    df.iloc[:,1:-i], df.iloc[:,0], test_size=0.20, random_state=random_state)\n",
        "    print('MAIN RESULTS')\n",
        "    # pos_weight = sum(Y_train[Y_train == 0]) / sum(Y_train[Y_train == 1])\n",
        "    # train_weight = sum(1 if x == 0 else 0 for x in Y_train)\\\n",
        "    #                     /sum(1 if x == 1 else 0 for x in Y_train)\n",
        "\n",
        "    # Parameter tuning\n",
        "    param_grid = {}\n",
        "    if model_name == 'lgb':\n",
        "      param_grid=lgb_param\n",
        "    elif model_name == 'rfc':\n",
        "      param_grid=rfc_param \n",
        "    elif model_name == 'SVM':\n",
        "       param_grid=svm_param\n",
        "    elif model_name == 'KNN':\n",
        "      param_grid=knn_param\n",
        "    elif model_name == 'XGB':\n",
        "      param_grid=xgb_param\n",
        "\n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    \n",
        "    # Normalization\n",
        "#     scaler = MinMaxScaler()\n",
        "    \n",
        "    \n",
        "    # Pipeline\n",
        "#     pipe = Pipeline([('scaler', scaler),\n",
        "#                      ('clf', model)])\n",
        "\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_train_scaled = pd.DataFrame(X_train_scaled)\n",
        "    X_train_scaled.index = X_train.index\n",
        "    X_train = pd.merge(X_train_scaled, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_train.columns = np.arange(X_train.shape[1])\n",
        "    \n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    X_test_scaled = pd.DataFrame(X_test_scaled)\n",
        "    X_test_scaled.index = X_test.index\n",
        "    X_test = pd.merge(X_test_scaled, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_test.columns = np.arange(X_test.shape[1])\n",
        "    X_test = X_test.iloc[:,:-1]\n",
        "\n",
        "   \n",
        "    groups = X_train.iloc[:,-1]\n",
        "    X_train = X_train.iloc[:,:-1]\n",
        "    # groups = []\n",
        "    # for index, row in X_train.iterrows():\n",
        "    #   if row.iloc[-1] == 1:\n",
        "    #     groups.append(1)\n",
        "    #   elif row.iloc[-2] == 1:\n",
        "    #     groups.append(2)\n",
        "    #   elif row.iloc[-3] == 1:\n",
        "    #     groups.append(3)\n",
        "    # groups = pd.Series(groups)\n",
        "\n",
        "    #SMOTE for Train Data to Balance Dataset and also to Increase Data Size\n",
        "    if SMOTEBool == True:\n",
        "        print('SMOTE is being applied to the train set...')\n",
        "        oversample = SMOTE()\n",
        "        X_train, Y_train = oversample.fit_resample(X_train, Y_train)\n",
        "    \n",
        "    # K-fold cross validation\n",
        "    # print('Starting StratifiedGroupKFold...')\n",
        "    # start = time.time()\n",
        "    cv = StratifiedGroupKFold(n_splits=cv_splits, random_state=1, shuffle=True)\n",
        "    cv_results = cross_val_score(model, X_train, Y_train, groups=groups, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "    # print('Cross Validation Accuracy: %.3f (%.3f)' % (np.mean(cv_results), np.std(cv_results)))\n",
        "    # end = time.time()\n",
        "    # print(f\"Total Time of StratifiedGroupKFold = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "\n",
        "    # Trial for Mahalanobis distance metric for KNN -- seems worse than euclidean so commented\n",
        "    if model_name == 'KNN' and distance == 'mahalanobis':\n",
        "        \n",
        "        param_grid = {'n_neighbors': list(range(3,21)),\n",
        "              'metric': ['mahalanobis'],\n",
        "              'algorithm': ['brute'],\n",
        "              'metric_params': [{'VI': np.linalg.inv(np.cov(X_train))}]\n",
        "        }\n",
        "    # GridSearch for Hyperparameters\n",
        "    print(\"Starting fitting into the model...\")\n",
        "    start = time.time()\n",
        "    model_ = GridSearchCV(model,           \n",
        "              param_grid = param_grid,    \n",
        "              scoring='accuracy',         \n",
        "              cv=cv,                      \n",
        "              n_jobs=-1)             \n",
        "    model_.fit(X_train, Y_train, groups=groups)\n",
        "    end = time.time()\n",
        "    print(f\"Total Time of model fit = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "\n",
        "    # model.set_params(**model_.best_params_)\n",
        "    # print(model.get_params())\n",
        "    \n",
        "    #permutationTest(model, X_train, Y_train, cv, groups)\n",
        "    \n",
        "#     # perform permutation importance\n",
        "#     results = permutation_importance(model_, X_train, Y_train, scoring='accuracy')\n",
        "#     # get importance\n",
        "#     importance = results.importances_mean\n",
        "#     # summarize feature importance\n",
        "#     for i,v in enumerate(importance):\n",
        "#         print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "#     # plot feature importance\n",
        "#     plt.bar([x for x in range(len(importance))], importance)\n",
        "#     plt.show()\n",
        "    \n",
        "    print(\"Tuned Hyperparameters :\", model_.best_params_)\n",
        "#     print(\"Tuned Best Accuracy :\", model_.best_score_)\n",
        "    \n",
        "    # Predictions\n",
        "    prediction = model_.predict(X_test)\n",
        "    pred_prob = model_.predict_proba(X_test)\n",
        "#     print(pred_prob)\n",
        "\n",
        "    # keep probabilities for the positive outcome only\n",
        "    pred_prob = pred_prob[:, 1]\n",
        "#     print(pred_prob_pos)\n",
        "    \n",
        "    # calculate roc curves\n",
        "    fpr, tpr, thresholds = roc_curve(Y_test, pred_prob)\n",
        "    \n",
        "    # calculate the g-mean for each threshold\n",
        "    gmeans = np.sqrt(tpr * (1-fpr))\n",
        "    \n",
        "    # locate the index of the largest g-mean\n",
        "    ix = np.argmax(gmeans)\n",
        "#     print('Best Threshold = %f, G-Mean = %.3f' % (thresholds[ix], gmeans[ix]))\n",
        "    print('Train Accuracy Score:', model_.score(X_train, Y_train))   \n",
        "    \n",
        "    # Probability of predictions adjusted to new threshold\n",
        "    # predict_model = [1 if y >= thresholds[ix] else 0 for y in pred_prob]\n",
        "    \n",
        "    # Original threshold\n",
        "    predict_model = [1 if y >= 0.5 else 0 for y in pred_prob]\n",
        "    predict_model = np.array(predict_model).reshape(-1,1)\n",
        "\n",
        "    print('Test Accuracy Score:', model_.score(X_test,Y_test))\n",
        "    print('AUC Score:', roc_auc_score(Y_test, predict_model))\n",
        "    print('F1 Score:', f1_score(Y_test, predict_model))\n",
        "    print('Precision Score:', precision_score(Y_test, predict_model))\n",
        "    print('Recall Score:', recall_score(Y_test, predict_model))\n",
        "    print('\\n')\n",
        "\n",
        "#     print(classification_report(Y_test, predict_model))\n",
        "#     print('Confusion Matrix:', '\\n', pd.DataFrame(confusion_matrix(Y_test, predict_model)))\n",
        "    \n",
        "#     score_train = model.score(X_train, Y_train)\n",
        "#     score_test = model.score(X_test, Y_test)\n",
        "    \n",
        "#     print(score_train, score_test)\n",
        "    return [model_, X_test, Y_test, groups]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ef2e79b",
      "metadata": {
        "id": "8ef2e79b"
      },
      "source": [
        "# MODEL PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7ad044f",
      "metadata": {
        "id": "c7ad044f"
      },
      "outputs": [],
      "source": [
        "def model_pca(df, model, model_name, featureCount, n_to_reach, SMOTEBool=False):\n",
        "    \n",
        "    print('PCA RESULTS')\n",
        "    df = pd.concat([df[df.columns[8:]], df[df.columns[6]]], ignore_index=True, axis=1)\n",
        "    i = df.shape[1] - (featureCount + 1)\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    df.iloc[:,1:-i], df.iloc[:,0], test_size=0.2, random_state=0)\n",
        "\n",
        "\n",
        "\n",
        "    param_grid = {}\n",
        "    pos_weight = sum(Y_train[Y_train == 0]) / sum(Y_train[Y_train == 1])\n",
        "    train_weight = sum(1 if x == 0 else 0 for x in Y_train)\\\n",
        "                        /sum(1 if x == 1 else 0 for x in Y_train)\n",
        "    # Parameter tuning\n",
        "    if model_name == 'lgb':\n",
        "        \n",
        "        param_grid = {\n",
        "#                     'max_depth': [2, 3, 4],\n",
        "#                     'num_leaves': [16,48,96],\n",
        "#                     'max_bin': [500,1000],\n",
        "#                     'boosting_type': ['dart'],\n",
        "#                     'learning_rate': [0.01,0.03],\n",
        "#                     'n_estimators' : [500,1000]\n",
        "                'boosting_type': ['gbdt', 'goss', 'dart'],\n",
        "                'num_leaves': list(range(10, 20)),\n",
        "                'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
        "                'num_iterations': list(range(50, 100)),\n",
        "                'early_stopping_rounds': list(range(1, 10)),\n",
        "                'scale_pos_weight': [pos_weight],\n",
        "                'max_depth':list(range(1,12)),\n",
        "                'max_bin': list(range(2, 30)),\n",
        "                'n_jobs' : [-1],\n",
        "                'path_smooth': list(range(2,15)),\n",
        "                'random_state': [0]\n",
        "                     }\n",
        "\n",
        "    \n",
        "    elif model_name == 'rfc':\n",
        "        \n",
        "        param_grid = {'bootstrap': [True],\n",
        "                       'max_depth': [2, 3, 4],\n",
        "                       'n_estimators': [100, 300, 500],\n",
        "                       'criterion' :['gini', 'entropy']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'SVM':\n",
        "        \n",
        "        param_grid = {'C': [0.01, 0.1, 1, 3, 5],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['linear']\n",
        "                     }\n",
        "        \n",
        "    \n",
        "    elif model_name == 'KNN':\n",
        "        \n",
        "        param_grid = {'n_neighbors': list(range(3,21)),\n",
        "              'metric': ['euclidean']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'XGB':\n",
        "        \n",
        "        \n",
        "        \n",
        "        param_grid = {'learning_rate':[0.01, 0.03, 0.05, 0.1],\n",
        "                'max_depth':[2,3,4],\n",
        "                'booster': ('gbtree', 'gblinear'),\n",
        "                'random_state': [0],\n",
        "                'n_jobs': [-1],\n",
        "                'scale_pos_weight': [pos_weight],\n",
        "                'gamma': [1, 5, 10],\n",
        "                'min_child_weight': list(range(3,8)),\n",
        "                'use_label_encoder': [False],\n",
        "                'early_stopping_rounds': list(range(3,10)),\n",
        "                'objective': ['binary:logistic'], \n",
        "                'eval_metric': ['auc'],\n",
        "                'verbosity': [0]\n",
        "                     }\n",
        "        \n",
        "       \n",
        "    # finding n_components for maintaining specified variance\n",
        "        # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    \n",
        "    # Normalization\n",
        "#     scaler = MinMaxScaler()\n",
        "    \n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "#     X_train_scaled = pd.DataFrame(X_train_scaled)\n",
        "#     X_train_scaled.index = X_train.index\n",
        "    \n",
        "    \n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "#     X_test_scaled = pd.DataFrame(X_test_scaled)\n",
        "#     X_test_scaled.index = X_test.index    \n",
        "    \n",
        "    print(\"Starting PCA...\")\n",
        "    start = time.time()\n",
        "    # pca = PCA()    \n",
        "    # X_pca_train = pca.fit_transform(X_train_scaled)\n",
        "    \n",
        "    # total_explained_variance = pca.explained_variance_ratio_.cumsum()\n",
        "    # n_over = len(total_explained_variance[total_explained_variance >= variance])\n",
        "    # n_to_reach = X_train.shape[1] - n_over + 1\n",
        "    # print(\"Number features: {}\\tTotal Variance Explained: {}\"\n",
        "    #       .format(n_to_reach, total_explained_variance[n_to_reach-1]))\n",
        "    \n",
        "    pca = PCA(n_components=n_to_reach)    \n",
        "    X_pca_train = pca.fit_transform(X_train_scaled)\n",
        "    X_pca_train = pd.DataFrame(X_pca_train)\n",
        "    X_pca_train.index = X_train.index\n",
        "    X_pca_train = pd.merge(X_pca_train, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_pca_train.columns = np.arange(X_pca_train.shape[1]) \n",
        "\n",
        "    X_pca_test = pca.transform(X_test_scaled)\n",
        "    X_pca_test = pd.DataFrame(X_pca_test)\n",
        "    X_pca_test.index = X_test.index\n",
        "    X_pca_test = pd.merge(X_pca_test, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_pca_test.columns = np.arange(X_pca_test.shape[1])\n",
        "    X_pca_test = X_pca_test.iloc[:,:-1]\n",
        "    \n",
        "    groups = X_pca_train.iloc[:,-1]\n",
        "    X_pca_train = X_pca_train.iloc[:,:-1]\n",
        "    end = time.time()\n",
        "    print(f\"Total Time of PCA = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "\n",
        "    #SMOTE for Train Data to Balance Dataset and also to Increase Data Size\n",
        "    if SMOTEBool == True:\n",
        "        oversample = SMOTE()\n",
        "        X_pca_train, Y_train = oversample.fit_resample(X_pca_train, Y_train)\n",
        "    \n",
        "    # K-fold cross validation\n",
        "    cv = StratifiedGroupKFold(n_splits=5, random_state=1, shuffle=True)\n",
        "#     cv_results = cross_val_score(model, X_pca_train, Y_train, groups=groups, cv=cv, scoring='accuracy')\n",
        "#     print('Cross Validation Accuracy: %.3f (%.3f)' % (np.mean(cv_results), np.std(cv_results)))\n",
        "        \n",
        "    # GridSearch for Hyperparameters\n",
        "    model_ = GridSearchCV(model,           # model\n",
        "              param_grid = param_grid,    # hyperparameters\n",
        "              scoring='accuracy',         # metric for scoring\n",
        "              cv=cv,                      # number of folds\n",
        "              n_jobs=-1)\n",
        "    print(\"Starting fitting into the model...\")\n",
        "    start = time.time()          \n",
        "    model_.fit(X_pca_train,Y_train, groups=groups)\n",
        "    end = time.time()\n",
        "    print(f\"Total Time of model fit = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "\n",
        "    \n",
        "    model.set_params(**model_.best_params_)\n",
        "    print(model.get_params())\n",
        "    #permutationTest(model, X_pca_train, Y_train, cv, groups)\n",
        "    \n",
        "#     # perform permutation importance\n",
        "#     results = permutation_importance(model_, X_pca_train, Y_train, scoring='accuracy')\n",
        "#     # get importance\n",
        "#     importance = results.importances_mean\n",
        "#     # summarize feature importance\n",
        "#     for i,v in enumerate(importance):\n",
        "#         print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "#     # plot feature importance\n",
        "#     plt.bar([x for x in range(len(importance))], importance)\n",
        "#     plt.show()\n",
        "    \n",
        "    \n",
        "    print(\"Tuned Hyperparameters :\", model_.best_params_)\n",
        "#     print(\"Tuned Best Accuracy :\", model_.best_score_)\n",
        "    \n",
        "    # Predictions\n",
        "    pred_prob = model_.predict_proba(X_pca_test)\n",
        "#     print(pred_prob)\n",
        "\n",
        "    # keep probabilities for the positive outcome only\n",
        "    pred_prob = pred_prob[:, 1]\n",
        "#     print(pred_prob_pos)\n",
        "    \n",
        "    # calculate roc curves\n",
        "    fpr, tpr, thresholds = roc_curve(Y_test, pred_prob)\n",
        "    \n",
        "    # calculate the g-mean for each threshold\n",
        "    gmeans = np.sqrt(tpr * (1-fpr))\n",
        "    \n",
        "    # locate the index of the largest g-mean\n",
        "    ix = np.argmax(gmeans)\n",
        "#     print('Best Threshold = %f, G-Mean = %.3f' % (thresholds[ix], gmeans[ix]))\n",
        "    print('Train Accuracy Score:', model_.score(X_pca_train, Y_train))   \n",
        "\n",
        "    # Probability of predictions adjusted to new threshold\n",
        "    predict_model = [1 if y >= thresholds[ix] else 0 for y in pred_prob]\n",
        "    \n",
        "    # Original threshold\n",
        "#     predict_model = [1 if y >= 0.5 else 0 for y in pred_prob]\n",
        "#     print(predict_model)\n",
        "\n",
        "    \n",
        "    #print(predict_lgb)\n",
        "    print('Test Accuracy Score:', accuracy_score(Y_test, predict_model))\n",
        "    print('AUC Score:', roc_auc_score(Y_test, predict_model))\n",
        "    print('F1 Score:', f1_score(Y_test, predict_model))\n",
        "    print('Precision Score:', precision_score(Y_test, predict_model))\n",
        "    print('Recall Score:', recall_score(Y_test, predict_model))\n",
        "    print('\\n')\n",
        "#     print(classification_report(Y_test, predict_model))\n",
        "#     print('Confusion Matrix:', '\\n', pd.DataFrame(confusion_matrix(Y_test, predict_model)))\n",
        "    \n",
        "#     score_train = model.score(X_train, Y_train)\n",
        "#     score_test = model.score(X_test, Y_test)\n",
        "    \n",
        "#     print(score_train, score_test)\n",
        "    return (f1_score(Y_test, predict_model), model_, X_pca_train, Y_train, cv, groups)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c055397d",
      "metadata": {
        "id": "c055397d"
      },
      "source": [
        "# MODEL TSNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebdb80d2",
      "metadata": {
        "id": "ebdb80d2"
      },
      "outputs": [],
      "source": [
        "def model_t_sne(df, model, model_name, featureCount, n_to_reach, SMOTEBool=False):\n",
        "    \n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    print('TSNE RESULTS')\n",
        "     # Test/Train Split\n",
        "    df = pd.concat([df[df.columns[8:]], df[df.columns[6]]], ignore_index=True, axis=1)\n",
        "    i = df.shape[1] - (featureCount + 1)\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    df.iloc[:,1:-i], df.iloc[:,0], test_size=0.2, random_state=0)\n",
        "#     print(X_train)\n",
        "\n",
        "    # Normalization\n",
        "#     scaler = MinMaxScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # pca = PCA()    \n",
        "    # X_tsne_train = pca.fit_transform(X_train_scaled)\n",
        "\n",
        "    \n",
        "    # total_explained_variance = pca.explained_variance_ratio_.cumsum()\n",
        "    # n_over = len(total_explained_variance[total_explained_variance >= variance])\n",
        "    # n_to_reach = X_train.shape[1] - n_over + 1\n",
        "    # print(\"Number features: {}\\tTotal Variance Explained: {}\"\n",
        "    #       .format(n_to_reach, total_explained_variance[n_to_reach-1]))\n",
        "    \n",
        "    # T-SNE\n",
        "    print(\"Starting TSNE...\")\n",
        "    start = time.time()    \n",
        "    tsne = TSNE(n_components=n_to_reach, \n",
        "                init='pca', random_state=0, method='exact', n_jobs=-1, learning_rate = 0.1, n_iter=2000)\n",
        "    X_tsne_train = tsne.fit_transform(X_train_scaled)\n",
        "    X_tsne_train = pd.DataFrame(X_tsne_train)\n",
        "    X_tsne_train.index = X_train.index\n",
        "    X_tsne_train = pd.merge(X_tsne_train, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_tsne_train.columns = np.arange(X_tsne_train.shape[1]) \n",
        "\n",
        "\n",
        "    X_tsne_test = tsne.fit_transform(X_test_scaled)\n",
        "    X_tsne_test = pd.DataFrame(X_tsne_test)\n",
        "    X_tsne_test.index = X_test.index\n",
        "    X_tsne_test = pd.merge(X_tsne_test, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_tsne_test.columns = np.arange(X_tsne_test.shape[1])\n",
        "    X_tsne_test = X_tsne_test.iloc[:,:-1]\n",
        "    \n",
        "    groups = X_tsne_train.iloc[:,-1]\n",
        "    X_tsne_train = X_tsne_train.iloc[:,:-1]\n",
        "    end = time.time()\n",
        "    print(f\"Total Time of TSNE = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "    \n",
        "    #SMOTE for Train Data to Balance Dataset and also to Increase Data Size\n",
        "    if SMOTEBool == True:\n",
        "        oversample = SMOTE()\n",
        "        X_tsne_train, Y_train = oversample.fit_resample(X_tsne_train, Y_train)\n",
        "    \n",
        "    \n",
        "    param_grid = {}\n",
        "    pos_weight = sum(Y_train[Y_train == 0]) / sum(Y_train[Y_train == 1])\n",
        "    train_weight = sum(1 if x == 0 else 0 for x in Y_train)\\\n",
        "                        /sum(1 if x == 1 else 0 for x in Y_train)\n",
        "    # Parameter tuning\n",
        "    if model_name == 'lgb':\n",
        "        \n",
        "        param_grid = {\n",
        "#                     'max_depth': [2, 3, 4],\n",
        "#                     'num_leaves': [16,48,96],\n",
        "#                     'max_bin': [500,1000],\n",
        "#                     'boosting_type': ['dart'],\n",
        "#                     'learning_rate': [0.01,0.03],\n",
        "#                     'n_estimators' : [500,1000]\n",
        "                'boosting_type': ['gbdt', 'goss', 'dart'],\n",
        "                'num_leaves': list(range(10, 20)),\n",
        "                'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
        "                'num_iterations': list(range(50, 100)),\n",
        "                'early_stopping_rounds': list(range(1, 10)),\n",
        "                'scale_pos_weight': [pos_weight],\n",
        "                'max_depth':list(range(1,12)),\n",
        "                'max_bin': list(range(2, 30)),\n",
        "                'n_jobs' : [-1],\n",
        "                'path_smooth': list(range(2,15)),\n",
        "                'random_state': [0]\n",
        "                     }\n",
        "\n",
        "    \n",
        "    elif model_name == 'rfc':\n",
        "        \n",
        "        param_grid = {'bootstrap': [True],\n",
        "                       'max_depth': [2, 3, 4],\n",
        "                       'n_estimators': [100, 300, 500],\n",
        "                       'criterion' :['gini', 'entropy']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'SVM':\n",
        "        \n",
        "        param_grid = {'C': [0.01, 0.1, 1, 3, 5],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['linear']\n",
        "                     }\n",
        "        \n",
        "    \n",
        "    elif model_name == 'KNN':\n",
        "        \n",
        "        param_grid = {'n_neighbors': list(range(3,21)),\n",
        "              'metric': ['euclidean']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'XGB':\n",
        "        \n",
        "        \n",
        "        \n",
        "        param_grid = {'learning_rate':[0.01, 0.03, 0.05, 0.1],\n",
        "                'max_depth':[2,3,4],\n",
        "                'booster': ('gbtree', 'gblinear'),\n",
        "                'random_state': [0],\n",
        "                'n_jobs': [-1],\n",
        "                'scale_pos_weight': [pos_weight],\n",
        "                'gamma': [1, 5, 10],\n",
        "                'min_child_weight': list(range(3,8)),\n",
        "                'use_label_encoder': [False],\n",
        "                'early_stopping_rounds': list(range(3,10)),\n",
        "                'objective': ['binary:logistic'], \n",
        "                'eval_metric': ['auc'],\n",
        "                'verbosity': [0]\n",
        "                     }\n",
        "\n",
        "    # K-fold cross validation\n",
        "    # print('Starting StratifiedGroupKFold...')\n",
        "    cv = StratifiedGroupKFold(n_splits=5, random_state=1, shuffle=True)\n",
        "#     cv_results = cross_val_score(model, X_tsne_train, Y_train,groups=groups, cv=cv, scoring='accuracy')\n",
        "#     print('Cross Validation Accuracy: %.3f (%.3f)' % (np.mean(cv_results), np.std(cv_results)))\n",
        "    \n",
        "#     permutationTest(model, X_tsne_train, Y_train, cv, groups)\n",
        "    \n",
        "    # GridSearch for Hyperparameters\n",
        "    print(\"Starting fitting into the model...\")\n",
        "    start = time.time()\n",
        "    model_ = GridSearchCV(model,           # model\n",
        "              param_grid = param_grid,    # hyperparameters\n",
        "              scoring='accuracy',         # metric for scoring\n",
        "              cv=cv,                    # number of folds\n",
        "              n_jobs=-1)             \n",
        "    model_.fit(X_tsne_train,Y_train, groups=groups)\n",
        "    end = time.time()\n",
        "    print(f\"Total Time of model fit = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "    \n",
        "#     # perform permutation importance\n",
        "#     results = permutation_importance(model_, X_tsne_train, Y_train, scoring='accuracy')\n",
        "#     # get importance\n",
        "#     importance = results.importances_mean\n",
        "#     # summarize feature importance\n",
        "#     for i,v in enumerate(importance):\n",
        "#         print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "#     # plot feature importance\n",
        "#     plt.bar([x for x in range(len(importance))], importance)\n",
        "#     plt.show()\n",
        "    \n",
        "    \n",
        "    print(\"Tuned Hyperparameters :\", model_.best_params_)\n",
        "    \n",
        "    model.set_params(**model_.best_params_)\n",
        "    print(model.get_params())\n",
        "    \n",
        "    #permutationTest(model, X_tsne_train, Y_train, cv, groups)\n",
        "    \n",
        "#     print(\"Tuned Best Accuracy :\", model_.best_score_)\n",
        "    \n",
        "    # Predictions\n",
        "    pred_prob = model_.predict_proba(X_tsne_test)\n",
        "#     print(pred_prob)\n",
        "\n",
        "    # keep probabilities for the positive outcome only\n",
        "    pred_prob = pred_prob[:, 1]\n",
        "#     print(pred_prob_pos)\n",
        "    \n",
        "    # calculate roc curves\n",
        "    fpr, tpr, thresholds = roc_curve(Y_test, pred_prob)\n",
        "    \n",
        "    # calculate the g-mean for each threshold\n",
        "    gmeans = np.sqrt(tpr * (1-fpr))\n",
        "    \n",
        "    # locate the index of the largest g-mean\n",
        "    ix = np.argmax(gmeans)\n",
        "#     print('Best Threshold = %f, G-Mean = %.3f' % (thresholds[ix], gmeans[ix]))\n",
        "    print('Train Accuracy Score:', model_.score(X_tsne_train, Y_train))\n",
        "\n",
        "    # Probability of predictions adjusted to new threshold\n",
        "    predict_model = [1 if y >= thresholds[ix] else 0 for y in pred_prob]\n",
        "    \n",
        "    # Original threshold\n",
        "#     predict_model = [1 if y >= 0.5 else 0 for y in pred_prob]\n",
        "#     print(predict_model)\n",
        "\n",
        "    \n",
        "    #print(predict_lgb)\n",
        "    print('Test Accuracy Score:', accuracy_score(Y_test, predict_model))\n",
        "    print('AUC Score:', roc_auc_score(Y_test, predict_model))\n",
        "    print('F1 Score:', f1_score(Y_test, predict_model))\n",
        "    print('Precision Score:', precision_score(Y_test, predict_model))\n",
        "    print('Recall Score:', recall_score(Y_test, predict_model))\n",
        "    print('\\n')\n",
        "#     print(classification_report(Y_test, predict_model))\n",
        "#     print('Confusion Matrix:', '\\n', pd.DataFrame(confusion_matrix(Y_test, predict_model)))\n",
        "    \n",
        "#     score_train = model.score(X_train, Y_train)\n",
        "#     score_test = model.score(X_test, Y_test)\n",
        "    \n",
        "#     print(score_train, score_test)\n",
        "    return (f1_score(Y_test, predict_model), model_, X_tsne_train,Y_train, cv, groups)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a138064f",
      "metadata": {
        "id": "a138064f"
      },
      "source": [
        "# MODEL ISOMAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "801ae2b5",
      "metadata": {
        "id": "801ae2b5"
      },
      "outputs": [],
      "source": [
        "def model_isomap(df, model, model_name, featureCount, n_to_reach, SMOTEBool=False):\n",
        "    \n",
        "    df = pd.concat([df[df.columns[8:]], df[df.columns[6]]], ignore_index=True, axis=1)\n",
        "    i = df.shape[1] - (featureCount + 1)\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    df.iloc[:,1:-i], df.iloc[:,0], test_size=0.2, random_state=0)\n",
        "\n",
        "    print('ISOMAP RESULTS')\n",
        "\n",
        "    \n",
        "\n",
        "    param_grid = {}\n",
        "    pos_weight = sum(Y_train[Y_train == 0]) / sum(Y_train[Y_train == 1])\n",
        "    train_weight = sum(1 if x == 0 else 0 for x in Y_train)\\\n",
        "                        /sum(1 if x == 1 else 0 for x in Y_train)\n",
        "    # Parameter tuning\n",
        "    if model_name == 'lgb':\n",
        "        \n",
        "        param_grid = {\n",
        "#                     'max_depth': [2, 3, 4],\n",
        "#                     'num_leaves': [16,48,96],\n",
        "#                     'max_bin': [500,1000],\n",
        "#                     'boosting_type': ['dart'],\n",
        "#                     'learning_rate': [0.01,0.03],\n",
        "#                     'n_estimators' : [500,1000]\n",
        "                'boosting_type': ['gbdt', 'goss', 'dart'],\n",
        "                'num_leaves': list(range(10, 20)),\n",
        "                'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
        "                'num_iterations': list(range(50, 100)),\n",
        "                'early_stopping_rounds': list(range(1, 10)),\n",
        "                'scale_pos_weight': [pos_weight],\n",
        "                'max_depth':list(range(1,12)),\n",
        "                'max_bin': list(range(2, 30)),\n",
        "                'n_jobs' : [-1],\n",
        "                'path_smooth': list(range(2,15)),\n",
        "                'random_state': [0]\n",
        "                     }\n",
        "\n",
        "    \n",
        "    elif model_name == 'rfc':\n",
        "        \n",
        "        param_grid = {'bootstrap': [True],\n",
        "                       'max_depth': [2, 3, 4],\n",
        "                       'n_estimators': [100, 300, 500],\n",
        "                       'criterion' :['gini', 'entropy']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'SVM':\n",
        "        \n",
        "        param_grid = {'C': [0.01, 0.1, 1, 3, 5],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['linear']\n",
        "                     }\n",
        "        \n",
        "    \n",
        "    elif model_name == 'KNN':\n",
        "        \n",
        "        param_grid = {'n_neighbors': list(range(3,21)),\n",
        "              'metric': ['euclidean']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'XGB':\n",
        "        \n",
        "        \n",
        "        \n",
        "        param_grid = {'learning_rate':[0.01, 0.03, 0.05, 0.1],\n",
        "                'max_depth':[2,3,4],\n",
        "                'booster': ('gbtree', 'gblinear'),\n",
        "                'random_state': [0],\n",
        "                'n_jobs': [-1],\n",
        "                'scale_pos_weight': [pos_weight],\n",
        "                'gamma': [1, 5, 10],\n",
        "                'min_child_weight': list(range(3,8)),\n",
        "                'use_label_encoder': [False],\n",
        "                'early_stopping_rounds': list(range(3,10)),\n",
        "                'objective': ['binary:logistic'], \n",
        "                'eval_metric': ['auc'],\n",
        "                'verbosity': [0]\n",
        "                     }\n",
        "        \n",
        "    \n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    \n",
        "    # Normalization\n",
        "#     scaler = MinMaxScaler()\n",
        "\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    # pca = PCA()    \n",
        "    # X_iso_train = pca.fit_transform(X_train_scaled)\n",
        "    \n",
        "    # total_explained_variance = pca.explained_variance_ratio_.cumsum()\n",
        "    # n_over = len(total_explained_variance[total_explained_variance >= variance])\n",
        "    # n_to_reach = X_train.shape[1] - n_over + 1\n",
        "    # print(\"Number features: {}\\tTotal Variance Explained: {}\"\n",
        "    #       .format(n_to_reach, total_explained_variance[n_to_reach-1]))\n",
        "    \n",
        "    print(\"Starting ISOMAP...\")\n",
        "    start = time.time()\n",
        "    iso = Isomap(n_components=n_to_reach)    \n",
        "    X_iso_train = iso.fit_transform(X_train_scaled)\n",
        "    X_iso_train = pd.DataFrame(X_iso_train)\n",
        "    X_iso_train.index = X_train.index\n",
        "    X_iso_train = pd.merge(X_iso_train, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_iso_train.columns = np.arange(X_iso_train.shape[1]) \n",
        "\n",
        "\n",
        "    X_iso_test = iso.transform(X_test_scaled)\n",
        "    X_iso_test = pd.DataFrame(X_iso_test)\n",
        "    X_iso_test.index = X_test.index\n",
        "    X_iso_test = pd.merge(X_iso_test, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_iso_test.columns = np.arange(X_iso_test.shape[1])\n",
        "    X_iso_test = X_iso_test.iloc[:,:-1]\n",
        "    \n",
        "    groups = X_iso_train.iloc[:,-1]\n",
        "    X_iso_train = X_iso_train.iloc[:,:-1]\n",
        "    end = time.time()\n",
        "    print(f\"Total Time of ISOMAP = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "\n",
        "    #SMOTE for Train Data to Balance Dataset and also to Increase Data Size\n",
        "    if SMOTEBool == True:\n",
        "        oversample = SMOTE()\n",
        "        X_iso_train, Y_train = oversample.fit_resample(X_iso_train, Y_train)\n",
        "    \n",
        "    # K-fold cross validation\n",
        "    # print('Starting StratifiedGroupKFold...')\n",
        "    cv = StratifiedGroupKFold(n_splits=5, random_state=1, shuffle=True)\n",
        "#     cv_results = cross_val_score(model, X_iso_train, Y_train, groups=groups, cv=cv, scoring='accuracy')\n",
        "#     print('Cross Validation Accuracy: %.3f (%.3f)' % (np.mean(cv_results), np.std(cv_results)))\n",
        "    \n",
        "#     permutationTest(model, X_iso_train, Y_train, cv, groups)\n",
        "    \n",
        "    # GridSearch for Hyperparameters\n",
        "    print(\"Starting fitting into the model...\")\n",
        "    start = time.time()\n",
        "    model_ = GridSearchCV(model,           # model\n",
        "              param_grid = param_grid,    # hyperparameters\n",
        "              scoring='accuracy',         # metric for scoring\n",
        "              cv=cv,                      # number of folds\n",
        "              n_jobs=-1)             \n",
        "    model_.fit(X_iso_train,Y_train, groups=groups)\n",
        "    end = time.time()\n",
        "    print(f\"Total Time of model fit = {str(datetime.timedelta(seconds=(end-start)))}\")\n",
        "\n",
        "\n",
        "    model.set_params(**model_.best_params_)\n",
        "    print(model.get_params())\n",
        "    \n",
        "    #permutationTest(model, X_iso_train, Y_train, cv, groups)\n",
        "    \n",
        "#     # perform permutation importance\n",
        "#     results = permutation_importance(model_, X_iso_train, Y_train, scoring='accuracy')\n",
        "#     # get importance\n",
        "#     importance = results.importances_mean\n",
        "#     # summarize feature importance\n",
        "#     for i,v in enumerate(importance):\n",
        "#         print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "#     # plot feature importance\n",
        "#     plt.bar([x for x in range(len(importance))], importance)\n",
        "#     plt.show()\n",
        "    \n",
        "    \n",
        "    print(\"Tuned Hyperparameters :\", model_.best_params_)\n",
        "#     print(\"Tuned Best Accuracy :\", model_.best_score_)\n",
        "    \n",
        "    # Predictions\n",
        "    pred_prob = model_.predict_proba(X_iso_test)\n",
        "#     print(pred_prob)\n",
        "\n",
        "    # keep probabilities for the positive outcome only\n",
        "    pred_prob = pred_prob[:, 1]\n",
        "#     print(pred_prob_pos)\n",
        "    \n",
        "    # calculate roc curves\n",
        "    fpr, tpr, thresholds = roc_curve(Y_test, pred_prob)\n",
        "    \n",
        "    # calculate the g-mean for each threshold\n",
        "    gmeans = np.sqrt(tpr * (1-fpr))\n",
        "    \n",
        "    # locate the index of the largest g-mean\n",
        "    ix = np.argmax(gmeans)\n",
        "#     print('Best Threshold = %f, G-Mean = %.3f' % (thresholds[ix], gmeans[ix]))\n",
        "    print('Train Accuracy Score:', model_.score(X_iso_train, Y_train))   \n",
        "  \n",
        "    # Probability of predictions adjusted to new threshold\n",
        "    predict_model = [1 if y >= thresholds[ix] else 0 for y in pred_prob]\n",
        "    \n",
        "    # Original threshold\n",
        "#     predict_model = [1 if y >= 0.5 else 0 for y in pred_prob]\n",
        "#     print(predict_model)\n",
        "\n",
        "    \n",
        "    #print(predict_lgb)\n",
        "    print('Test Accuracy Score:', accuracy_score(Y_test, predict_model))\n",
        "    print('AUC Score:', roc_auc_score(Y_test, predict_model))\n",
        "    print('F1 Score:', f1_score(Y_test, predict_model))\n",
        "    print('Precision Score:', precision_score(Y_test, predict_model))\n",
        "    print('Recall Score:', recall_score(Y_test, predict_model))\n",
        "    print('\\n')\n",
        "#     print(classification_report(Y_test, predict_model))\n",
        "#     print('Confusion Matrix:', '\\n', pd.DataFrame(confusion_matrix(Y_test, predict_model)))\n",
        "    \n",
        "#     score_train = model.score(X_train, Y_train)\n",
        "#     score_test = model.score(X_test, Y_test)\n",
        "    \n",
        "#     print(score_train, score_test)\n",
        "    return (f1_score(Y_test, predict_model), model_, X_iso_train, Y_train, cv, groups)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a237fda6",
      "metadata": {
        "id": "a237fda6"
      },
      "outputs": [],
      "source": [
        "def main_model_WithinEachIndividual(df, model, model_name, featureCount, SMOTEBool=False):\n",
        "    \n",
        " \n",
        "    df = pd.concat([df[df.columns[8:]], df[df.columns[6]]], ignore_index=True, axis=1)\n",
        "    i = df.shape[1] - (featureCount + 1)\n",
        "    print(i)\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    df.iloc[:,1:-i], df.iloc[:,0], test_size=0.20, random_state=0)\n",
        "    print('MAIN RESULTS')\n",
        "    \n",
        "    param_grid = {}\n",
        "    \n",
        "    # Parameter tuning\n",
        "    if model_name == 'lgb':\n",
        "        \n",
        "        train_weight = sum(1 if x == 0 else 0 for x in Y_train)\\\n",
        "                        /sum(1 if x == 1 else 0 for x in Y_train)\n",
        "\n",
        "        param_grid = {'max_depth': [2, 3, 4],\n",
        "                    'num_leaves': [16,48,96],\n",
        "                    'max_bin': [500,1000],\n",
        "                    'boosting_type': ['dart'],\n",
        "                    'learning_rate': [0.01,0.03],\n",
        "                    'n_estimators' : [500,1000]\n",
        "                     }\n",
        "    \n",
        "    elif model_name == 'rfc':\n",
        "        \n",
        "        param_grid = {'bootstrap': [True],\n",
        "                       'max_depth': [2, 3, 4],\n",
        "                       'n_estimators': [100, 300, 500],\n",
        "                       'criterion' :['gini', 'entropy']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'SVM':\n",
        "        \n",
        "        param_grid = {'C': [0.01, 0.1, 1, 3, 5],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['linear']\n",
        "                     }\n",
        "        \n",
        "    \n",
        "    elif model_name == 'KNN':\n",
        "        \n",
        "        param_grid = {'n_neighbors': list(range(3,21)),\n",
        "              'metric': ['euclidean']\n",
        "                     }\n",
        "        \n",
        "    elif model_name == 'XGB':\n",
        "        \n",
        "        param_grid = {'learning_rate':[0.01, 0.03, 0.05, 0.1],\n",
        "                'max_depth':[2,3,4],\n",
        "                'booster': ('gbtree', 'gblinear'),\n",
        "                'random_state': [0],\n",
        "                'n_jobs': [-1],\n",
        "                'gamma': [1, 5, 10],\n",
        "                'min_child_weight': list(range(3,8)),\n",
        "                'use_label_encoder': [False],\n",
        "                'objective': ['binary:logistic'], \n",
        "                'eval_metric': ['error'],\n",
        "                'verbosity': [0]\n",
        "                     } \n",
        "        \n",
        "        \n",
        "        \n",
        "       \n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    \n",
        "    # Normalization\n",
        "#     scaler = MinMaxScaler()\n",
        "    \n",
        "    \n",
        "    # Pipeline\n",
        "#     pipe = Pipeline([('scaler', scaler),\n",
        "#                      ('clf', model)])\n",
        "\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_train_scaled = pd.DataFrame(X_train_scaled)\n",
        "    X_train_scaled.index = X_train.index\n",
        "    X_train = pd.merge(X_train_scaled, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_train.columns = np.arange(X_train.shape[1])\n",
        "    \n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    X_test_scaled = pd.DataFrame(X_test_scaled)\n",
        "    X_test_scaled.index = X_test.index\n",
        "    X_test = pd.merge(X_test_scaled, df[df.columns[-i:]], left_index=True, right_index=True)\n",
        "    X_test.columns = np.arange(X_test.shape[1])\n",
        "    X_test = X_test.iloc[:,:-1]\n",
        "    \n",
        "    groups = X_train.iloc[:,-1]\n",
        "    X_train = X_train.iloc[:,:-1]\n",
        "    \n",
        "    if SMOTEBool == True:\n",
        "        oversample = SMOTE()\n",
        "        X_train, Y_train = oversample.fit_resample(X_train, Y_train)\n",
        "    \n",
        "    # K-fold cross validation\n",
        "    cv = StratifiedGroupKFold(n_splits=5, random_state=1, shuffle=True)\n",
        "#     cv_results = cross_val_score(model, X_train, Y_train, groups=groups, cv=cv, scoring='accuracy')\n",
        "#     print('Cross Validation Accuracy: %.3f (%.3f)' % (np.mean(cv_results), np.std(cv_results)))\n",
        "    \n",
        "    \n",
        "#     permutationTest(model, X_train, Y_train, cv, groups)\n",
        "       \n",
        "    \n",
        "    # Randomized Search for Hyperparameters\n",
        "#     model_ = RandomizedSearchCV(pipe, param_grid, scoring='accuracy',cv=cv, random_state=0)\n",
        "#     model_.fit(X_train,Y_train)\n",
        "    \n",
        "    # GridSearch for Hyperparameters\n",
        "    \n",
        "    model_ = GridSearchCV(model,           # model\n",
        "              param_grid = param_grid,    # hyperparameters\n",
        "              scoring='accuracy',         # metric for scoring\n",
        "              cv=cv                      # number of folds\n",
        "              )             \n",
        "    model_.fit(X_train, Y_train, groups=groups)\n",
        "    \n",
        "    model.set_params(**model_.best_params_)\n",
        "    print(model.get_params())\n",
        "    permutationTest(model, X_train, Y_train, cv, groups)\n",
        "    \n",
        "#     # perform permutation importance\n",
        "#     results = permutation_importance(model_, X_train, Y_train, scoring='accuracy')\n",
        "#     # get importance\n",
        "#     importance = results.importances_mean\n",
        "#     # summarize feature importance\n",
        "#     for i,v in enumerate(importance):\n",
        "#         print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "#     # plot feature importance\n",
        "#     plt.bar([x for x in range(len(importance))], importance)\n",
        "#     plt.show()\n",
        "    \n",
        "    print(\"Tuned Hyperparameters :\", model_.best_params_)\n",
        "#     print(\"Tuned Best Accuracy :\", model_.best_score_)\n",
        "    \n",
        "    # Predictions\n",
        "    pred_prob = model_.predict_proba(X_test)\n",
        "#     print(pred_prob)\n",
        "\n",
        "    # keep probabilities for the positive outcome only\n",
        "    pred_prob = pred_prob[:, 1]\n",
        "#     print(pred_prob_pos)\n",
        "    \n",
        "    # calculate roc curves\n",
        "    fpr, tpr, thresholds = roc_curve(Y_test, pred_prob)\n",
        "    \n",
        "    # calculate the g-mean for each threshold\n",
        "    gmeans = np.sqrt(tpr * (1-fpr))\n",
        "    \n",
        "    # locate the index of the largest g-mean\n",
        "    ix = np.argmax(gmeans)\n",
        "#     print('Best Threshold = %f, G-Mean = %.3f' % (thresholds[ix], gmeans[ix]))\n",
        "    print('Train Accuracy Score:', model_.score(X_train, Y_train))   \n",
        "    \n",
        "    # Probability of predictions adjusted to new threshold\n",
        "    predict_model = [1 if y >= thresholds[ix] else 0 for y in pred_prob]\n",
        "    \n",
        "    # Original threshold\n",
        "#     predict_model = [1 if y >= 0.5 else 0 for y in pred_prob]\n",
        "#     print(predict_model)\n",
        "\n",
        "    \n",
        "    #print(predict_lgb)\n",
        "    print('Test Accuracy Score:', accuracy_score(Y_test, predict_model))\n",
        "    print('AUC Score:', roc_auc_score(Y_test, predict_model))\n",
        "    print('F1 Score:', f1_score(Y_test, predict_model))\n",
        "    print('Precision Score:', precision_score(Y_test, predict_model))\n",
        "    print('Recall Score:', recall_score(Y_test, predict_model))\n",
        "    print('\\n')\n",
        "#     print(classification_report(Y_test, predict_model))\n",
        "#     print('Confusion Matrix:', '\\n', pd.DataFrame(confusion_matrix(Y_test, predict_model)))\n",
        "    \n",
        "#     score_train = model.score(X_train, Y_train)\n",
        "#     score_test = model.score(X_test, Y_test)\n",
        "    \n",
        "#     print(score_train, score_test)\n",
        "    return f1_score(Y_test, predict_model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "307.188px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}